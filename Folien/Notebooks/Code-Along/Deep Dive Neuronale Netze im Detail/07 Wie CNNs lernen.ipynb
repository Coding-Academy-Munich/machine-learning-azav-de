{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d09fab7fbaa4eee9",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "<img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRw\n",
    "Oi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMTExLjE2MSIgaGVpZ2h0PSIxMzQuNjY4\n",
    "IiB2ZXJzaW9uPSIxLjAiPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYyI+PHN0b3Agb2Zmc2V0\n",
    "PSIwIiBzdHlsZT0ic3RvcC1jb2xvcjojYjhiOGI4O3N0b3Atb3BhY2l0eTouNDk4MDM5MjIiLz48\n",
    "c3RvcCBvZmZzZXQ9IjEiIHN0eWxlPSJzdG9wLWNvbG9yOiM3ZjdmN2Y7c3RvcC1vcGFjaXR5OjAi\n",
    "Lz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYSI+PHN0b3Agb2Zmc2V0PSIw\n",
    "IiBzdHlsZT0ic3RvcC1jb2xvcjojZmZkNDNiO3N0b3Atb3BhY2l0eToxIi8+PHN0b3Agb2Zmc2V0\n",
    "PSIxIiBzdHlsZT0ic3RvcC1jb2xvcjojZmZlODczO3N0b3Atb3BhY2l0eToxIi8+PC9saW5lYXJH\n",
    "cmFkaWVudD48bGluZWFyR3JhZGllbnQgaWQ9ImIiPjxzdG9wIG9mZnNldD0iMCIgc3R5bGU9InN0\n",
    "b3AtY29sb3I6IzVhOWZkNDtzdG9wLW9wYWNpdHk6MSIvPjxzdG9wIG9mZnNldD0iMSIgc3R5bGU9\n",
    "InN0b3AtY29sb3I6IzMwNjk5ODtzdG9wLW9wYWNpdHk6MSIvPjwvbGluZWFyR3JhZGllbnQ+PGxp\n",
    "bmVhckdyYWRpZW50IHhsaW5rOmhyZWY9IiNhIiBpZD0iZSIgeDE9IjE1MC45NjEiIHgyPSIxMTIu\n",
    "MDMxIiB5MT0iMTkyLjM1MiIgeTI9IjEzNy4yNzMiIGdyYWRpZW50VHJhbnNmb3JtPSJtYXRyaXgo\n",
    "LjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRVbml0cz0idXNlclNw\n",
    "YWNlT25Vc2UiLz48bGluZWFyR3JhZGllbnQgeGxpbms6aHJlZj0iI2IiIGlkPSJkIiB4MT0iMjYu\n",
    "NjQ5IiB4Mj0iMTM1LjY2NSIgeTE9IjIwLjYwNCIgeTI9IjExNC4zOTgiIGdyYWRpZW50VHJhbnNm\n",
    "b3JtPSJtYXRyaXgoLjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRV\n",
    "bml0cz0idXNlclNwYWNlT25Vc2UiLz48cmFkaWFsR3JhZGllbnQgeGxpbms6aHJlZj0iI2MiIGlk\n",
    "PSJmIiBjeD0iNjEuNTE5IiBjeT0iMTMyLjI4NiIgcj0iMjkuMDM3IiBmeD0iNjEuNTE5IiBmeT0i\n",
    "MTMyLjI4NiIgZ3JhZGllbnRUcmFuc2Zvcm09Im1hdHJpeCgwIC0uMjM5OTUgMS4wNTQ2NyAwIC04\n",
    "My43IDE0Mi40NjIpIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIvPjwvZGVmcz48cGF0\n",
    "aCBkPSJNNTQuOTE5IDBjLTQuNTg0LjAyMi04Ljk2MS40MTMtMTIuODEzIDEuMDk1QzMwLjc2IDMu\n",
    "MDk5IDI4LjcgNy4yOTUgMjguNyAxNS4wMzJ2MTAuMjE5aDI2LjgxM3YzLjQwNkgxOC42MzhjLTcu\n",
    "NzkzIDAtMTQuNjE2IDQuNjg0LTE2Ljc1IDEzLjU5NC0yLjQ2MiAxMC4yMTMtMi41NzEgMTYuNTg2\n",
    "IDAgMjcuMjUgMS45MDUgNy45MzggNi40NTcgMTMuNTk0IDE0LjI1IDEzLjU5NGg5LjIxOHYtMTIu\n",
    "MjVjMC04Ljg1IDcuNjU3LTE2LjY1NyAxNi43NS0xNi42NTdoMjYuNzgyYzcuNDU0IDAgMTMuNDA2\n",
    "LTYuMTM4IDEzLjQwNi0xMy42MjV2LTI1LjUzYzAtNy4yNjctNi4xMy0xMi43MjYtMTMuNDA2LTEz\n",
    "LjkzOEM2NC4yODIuMzI4IDU5LjUwMi0uMDIgNTQuOTE4IDBtLTE0LjUgOC4yMmMyLjc3IDAgNS4w\n",
    "MzEgMi4yOTggNS4wMzEgNS4xMjUgMCAyLjgxNi0yLjI2MiA1LjA5My01LjAzMSA1LjA5My0yLjc4\n",
    "IDAtNS4wMzEtMi4yNzctNS4wMzEtNS4wOTMgMC0yLjgyNyAyLjI1MS01LjEyNSA1LjAzLTUuMTI1\n",
    "IiBzdHlsZT0iZmlsbDp1cmwoI2QpO2ZpbGwtb3BhY2l0eToxIi8+PHBhdGggZD0iTTg1LjYzOCAy\n",
    "OC42NTd2MTEuOTA2YzAgOS4yMzEtNy44MjYgMTctMTYuNzUgMTdINDIuMTA2Yy03LjMzNiAwLTEz\n",
    "LjQwNiA2LjI3OS0xMy40MDYgMTMuNjI1Vjk2LjcyYzAgNy4yNjYgNi4zMTkgMTEuNTQgMTMuNDA2\n",
    "IDEzLjYyNSA4LjQ4OCAyLjQ5NSAxNi42MjcgMi45NDYgMjYuNzgyIDAgNi43NS0xLjk1NSAxMy40\n",
    "MDYtNS44ODggMTMuNDA2LTEzLjYyNVY4Ni41SDU1LjUxM3YtMy40MDVIOTUuN2M3Ljc5MyAwIDEw\n",
    "LjY5Ni01LjQzNiAxMy40MDYtMTMuNTk0IDIuOC04LjM5OSAyLjY4LTE2LjQ3NiAwLTI3LjI1LTEu\n",
    "OTI1LTcuNzU4LTUuNjA0LTEzLjU5NC0xMy40MDYtMTMuNTk0ek03MC41NzUgOTMuMzEzYzIuNzgg\n",
    "MCA1LjAzMSAyLjI3OCA1LjAzMSA1LjA5NCAwIDIuODI3LTIuMjUxIDUuMTI1LTUuMDMxIDUuMTI1\n",
    "LTIuNzcgMC01LjAzMS0yLjI5OC01LjAzMS01LjEyNSAwLTIuODE2IDIuMjYxLTUuMDk0IDUuMDMx\n",
    "LTUuMDk0IiBzdHlsZT0iZmlsbDp1cmwoI2UpO2ZpbGwtb3BhY2l0eToxIi8+PGVsbGlwc2UgY3g9\n",
    "IjU1LjgxNyIgY3k9IjEyNy43MDEiIHJ4PSIzNS45MzEiIHJ5PSI2Ljk2NyIgc3R5bGU9Im9wYWNp\n",
    "dHk6LjQ0MzgyO2ZpbGw6dXJsKCNmKTtmaWxsLW9wYWNpdHk6MTtmaWxsLXJ1bGU6bm9uemVybztz\n",
    "dHJva2U6bm9uZTtzdHJva2Utd2lkdGg6MTUuNDE3NDtzdHJva2UtbWl0ZXJsaW1pdDo0O3N0cm9r\n",
    "ZS1kYXNoYXJyYXk6bm9uZTtzdHJva2Utb3BhY2l0eToxIi8+PC9zdmc+\n",
    "\"\n",
    "     style=\"display:block;margin:auto;width:10%\" alt=\"Python Logo\"/>\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align:center; font-size:200%;\">\n",
    " <b>Wie CNNs lernen</b>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"text-align:center;\">Dr. Matthias H√∂lzl</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ae969dc61e604",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Die Magie der Schichten\n",
    "\n",
    "- CNNs haben mehrere Convolutional Layers\n",
    "- Jede Schicht lernt unterschiedliche Dinge\n",
    "- **Hierarchisches Lernen**: Von einfach zu komplex\n",
    "- Schauen wir uns das genauer an!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ec2e1a4aa082e",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd3d6249a7a8c3",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5fc97ce8470a68",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Schicht 1: Einfache Kanten\n",
    "\n",
    "- Die **erste Schicht** lernt einfache Muster\n",
    "- Haupts√§chlich: **Kanten** und **Linien**\n",
    "- Horizontal, vertikal, diagonal\n",
    "- Diese sind die \"Bausteine\" f√ºr komplexere Muster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6883b455f0efb72d",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Visualisierung: Erste-Schicht-Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b350c37eb6bb901f",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Create example filters that first layer might learn\n",
    "first_layer_filters = {\n",
    "    'Vertical Edge': np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]]),\n",
    "    'Horizontal Edge': np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]]),\n",
    "    'Diagonal \\\\': np.array([[-1, 0, 0], [0, 1, 0], [0, 0, 1]]),\n",
    "    'Diagonal /': np.array([[0, 0, -1], [0, 1, 0], [1, 0, 0]]),\n",
    "    'Corner': np.array([[-1, -1, 0], [-1, 2, 0], [0, 0, 0]]),\n",
    "    'Blob': np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c0314591c2b8f",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_first_layer_filters():\n",
    "    \"\"\"Plot example filters from first layer\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for idx, (name, kernel) in enumerate(first_layer_filters.items()):\n",
    "        # Normalize for visualization\n",
    "        vmin, vmax = kernel.min(), kernel.max()\n",
    "        im = axes[idx].imshow(kernel, cmap='RdBu', vmin=-2, vmax=2)\n",
    "        axes[idx].set_title(name, fontsize=12, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "        # Add colorbar\n",
    "        plt.colorbar(im, ax=axes[idx], fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.suptitle('First Layer Filters: Simple Edges', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b0b9fd1642687",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4fd6e37f743ffd2",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Schicht 2: Formen und Texturen\n",
    "\n",
    "- Die **zweite Schicht** kombiniert Kanten\n",
    "- Lernt: **Ecken**, **Kurven**, **einfache Formen**\n",
    "- Auch: **Texturen** (z.B. gepunktet, gestreift)\n",
    "- Komplexer als Schicht 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5316773019bf9fd0",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Konzeptuelle Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fafaf798bb5c01",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_layer_hierarchy():\n",
    "    \"\"\"Plot conceptual hierarchy of what each layer learns\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Layer 1: Edges\n",
    "    layer1_text = [\"Vertical\\nEdges\", \"Horizontal\\nEdges\", \"Diagonal\\nEdges\", \"Colors\"]\n",
    "    axes[0].text(0.5, 0.9, 'Layer 1', ha='center', va='top',\n",
    "                fontsize=16, fontweight='bold', transform=axes[0].transAxes)\n",
    "    for i, text in enumerate(layer1_text):\n",
    "        axes[0].text(0.25 + (i % 2) * 0.5, 0.7 - (i // 2) * 0.3, text,\n",
    "                    ha='center', va='center', fontsize=11, transform=axes[0].transAxes,\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Layer 2: Shapes\n",
    "    layer2_text = [\"Corners\", \"Curves\", \"Simple\\nShapes\", \"Textures\"]\n",
    "    axes[1].text(0.5, 0.9, 'Layer 2', ha='center', va='top',\n",
    "                fontsize=16, fontweight='bold', transform=axes[1].transAxes)\n",
    "    for i, text in enumerate(layer2_text):\n",
    "        axes[1].text(0.25 + (i % 2) * 0.5, 0.7 - (i // 2) * 0.3, text,\n",
    "                    ha='center', va='center', fontsize=11, transform=axes[1].transAxes,\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7))\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Layer 3: Objects\n",
    "    layer3_text = [\"Eyes\", \"Wheels\", \"Doors\", \"Letters\"]\n",
    "    axes[2].text(0.5, 0.9, 'Layer 3+', ha='center', va='top',\n",
    "                fontsize=16, fontweight='bold', transform=axes[2].transAxes)\n",
    "    for i, text in enumerate(layer3_text):\n",
    "        axes[2].text(0.25 + (i % 2) * 0.5, 0.7 - (i // 2) * 0.3, text,\n",
    "                    ha='center', va='center', fontsize=11, transform=axes[2].transAxes,\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.suptitle('Hierarchical Learning in CNNs', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af1a231fb991412",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4aa243438c74a6f",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Schicht 3+: Objektteile\n",
    "\n",
    "- **Tiefere Schichten** kombinieren Formen\n",
    "- Lernen **Objektteile**\n",
    "- Beispiele:\n",
    "  - Augen, Nasen (f√ºr Gesichter)\n",
    "  - R√§der, Fenster (f√ºr Autos)\n",
    "  - Buchstaben, Ziffern (f√ºr Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b432f01bc9af5",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Letzte Schichten: Ganze Objekte\n",
    "\n",
    "- Die **letzten Schichten** kombinieren alles\n",
    "- Erkennen **komplette Objekte**\n",
    "- Beispiele:\n",
    "  - Gesichter\n",
    "  - Autos\n",
    "  - Tiere\n",
    "  - Geb√§ude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fff558979da711f",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Die Hierarchie im √úberblick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b004782581b27d",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_cnn_hierarchy_flow():\n",
    "    \"\"\"Plot the flow from pixels to objects\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    # Define layers with their learnings\n",
    "    layers = [\n",
    "        {'y': 5, 'name': 'Input Image', 'learns': ['Raw Pixels'], 'color': 'white'},\n",
    "        {'y': 4, 'name': 'Conv Layer 1', 'learns': ['Edges', 'Lines', 'Colors'], 'color': 'lightblue'},\n",
    "        {'y': 3, 'name': 'Conv Layer 2', 'learns': ['Corners', 'Curves', 'Textures'], 'color': 'lightcoral'},\n",
    "        {'y': 2, 'name': 'Conv Layer 3', 'learns': ['Simple Parts', 'Patterns'], 'color': 'lightgreen'},\n",
    "        {'y': 1, 'name': 'Dense Layers', 'learns': ['Complete Objects'], 'color': 'lightyellow'},\n",
    "    ]\n",
    "\n",
    "    for i, layer in enumerate(layers):\n",
    "        # Draw layer box\n",
    "        rect = plt.Rectangle((1, layer['y'] - 0.3), 12, 0.6,\n",
    "                            facecolor=layer['color'], edgecolor='black', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Layer name\n",
    "        ax.text(1.5, layer['y'], layer['name'], fontsize=12, fontweight='bold',\n",
    "               va='center', ha='left')\n",
    "\n",
    "        # What it learns\n",
    "        learns_text = ' | '.join(layer['learns'])\n",
    "        ax.text(11.5, layer['y'], learns_text, fontsize=10,\n",
    "               va='center', ha='right', style='italic')\n",
    "\n",
    "        # Arrow to next layer\n",
    "        if i < len(layers) - 1:\n",
    "            ax.arrow(7, layer['y'] - 0.4, 0, -0.15,\n",
    "                    head_width=0.3, head_length=0.05, fc='black', ec='black')\n",
    "\n",
    "    ax.set_xlim(0, 13)\n",
    "    ax.set_ylim(0, 6)\n",
    "    ax.axis('off')\n",
    "    ax.set_title('From Pixels to Objects: The CNN Hierarchy',\n",
    "                fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04e6c38e4b29319",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aea6a5ccf247b7a9",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Warum funktioniert das?\n",
    "\n",
    "- **Komposition**: Komplexe Dinge aus einfachen Bausteinen\n",
    "- **Wiederverwendung**: Die gleiche Kante kann in vielen Objekten vorkommen\n",
    "- **Abstraktion**: Jede Schicht abstrahiert mehr\n",
    "- **Nat√ºrliche Hierarchie**: So funktioniert auch unsere visuelle Wahrnehmung!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692723573416d59",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Beispiel: Gesichtserkennung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f7fffd6e38a18",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_face_recognition_hierarchy():\n",
    "    \"\"\"Plot how CNNs might learn to recognize faces\"\"\"\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "    # Input\n",
    "    axes[0].text(0.5, 0.5, 'üë§\\nInput\\nFace Image', ha='center', va='center',\n",
    "                fontsize=14, transform=axes[0].transAxes,\n",
    "                bbox=dict(boxstyle='round', facecolor='white', edgecolor='black', linewidth=2))\n",
    "    axes[0].set_title('Input', fontsize=12, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Layer 1\n",
    "    layer1_features = ['‚Äî\\nHorizontal', '|\\nVertical', '/\\nDiagonal']\n",
    "    for i, feat in enumerate(layer1_features):\n",
    "        axes[1].text(0.5, 0.75 - i*0.3, feat, ha='center', va='center',\n",
    "                    fontsize=10, transform=axes[1].transAxes,\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "    axes[1].set_title('Layer 1: Edges', fontsize=12, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Layer 2\n",
    "    layer2_features = ['‚óã\\nCurves', '‚ó¢\\nCorners', '‚ñì\\nTextures']\n",
    "    for i, feat in enumerate(layer2_features):\n",
    "        axes[2].text(0.5, 0.75 - i*0.3, feat, ha='center', va='center',\n",
    "                    fontsize=10, transform=axes[2].transAxes,\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7))\n",
    "    axes[2].set_title('Layer 2: Shapes', fontsize=12, fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    # Layer 3+\n",
    "    layer3_features = ['üëÅ\\nEyes', 'üëÉ\\nNose', 'üëÑ\\nMouth']\n",
    "    for i, feat in enumerate(layer3_features):\n",
    "        axes[3].text(0.5, 0.75 - i*0.3, feat, ha='center', va='center',\n",
    "                    fontsize=10, transform=axes[3].transAxes,\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "    axes[3].set_title('Layer 3+: Face Parts', fontsize=12, fontweight='bold')\n",
    "    axes[3].axis('off')\n",
    "\n",
    "    plt.suptitle('Learning to Recognize Faces', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc38cc9e41e93728",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf4ff063b7094130",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Transfer Learning\n",
    "\n",
    "- CNNs lernen **allgemeine Features**\n",
    "- Fr√ºhe Schichten (Kanten) sind f√ºr fast alle Bilder n√ºtzlich\n",
    "- Man kann ein trainiertes Netz nehmen und f√ºr neue Aufgaben anpassen\n",
    "- **Transfer Learning**: Nutze bereits gelernte Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbad1bc4e31ee37",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Transfer Learning Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab8f3ee68aa3df",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_transfer_learning():\n",
    "    \"\"\"Visualize transfer learning concept\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Pre-trained on ImageNet\n",
    "    axes[0].text(0.5, 0.9, 'Pre-trained on ImageNet\\n(1000 categories)', ha='center',\n",
    "                fontsize=12, fontweight='bold', transform=axes[0].transAxes)\n",
    "\n",
    "    layers_pretrained = [\n",
    "        ('Conv Layers\\n(Frozen)', 'lightblue', 0.6),\n",
    "        ('Dense Layer\\n(Frozen)', 'lightcoral', 0.3)\n",
    "    ]\n",
    "\n",
    "    for i, (name, color, y) in enumerate(layers_pretrained):\n",
    "        rect = plt.Rectangle((0.2, y), 0.6, 0.15, facecolor=color,\n",
    "                            edgecolor='black', linewidth=2, transform=axes[0].transAxes)\n",
    "        axes[0].add_patch(rect)\n",
    "        axes[0].text(0.5, y + 0.075, name, ha='center', va='center',\n",
    "                    fontsize=10, transform=axes[0].transAxes)\n",
    "\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Fine-tuned for new task\n",
    "    axes[1].text(0.5, 0.9, 'Fine-tuned for Cats vs Dogs\\n(2 categories)', ha='center',\n",
    "                fontsize=12, fontweight='bold', transform=axes[1].transAxes)\n",
    "\n",
    "    layers_finetuned = [\n",
    "        ('Conv Layers\\n(Frozen/Reused)', 'lightblue', 0.6),\n",
    "        ('New Dense Layer\\n(Trained)', 'lightgreen', 0.3)\n",
    "    ]\n",
    "\n",
    "    for i, (name, color, y) in enumerate(layers_finetuned):\n",
    "        rect = plt.Rectangle((0.2, y), 0.6, 0.15, facecolor=color,\n",
    "                            edgecolor='black', linewidth=2, transform=axes[1].transAxes)\n",
    "        axes[1].add_patch(rect)\n",
    "        axes[1].text(0.5, y + 0.075, name, ha='center', va='center',\n",
    "                    fontsize=10, transform=axes[1].transAxes)\n",
    "\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.suptitle('Transfer Learning: Reuse Pre-trained Features', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ee5f3faf08b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf7943720ed81b16",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Visualisierung von gelernten Features\n",
    "\n",
    "- Man kann visualisieren, was Filter in echten CNNs gelernt haben\n",
    "- Erste Schicht: Tats√§chlich Kanten und Farben!\n",
    "- Tiefere Schichten: Komplexere Muster\n",
    "- Best√§tigt unsere Theorie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e0f169dcac525",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Zusammenfassung\n",
    "\n",
    "- **Hierarchisches Lernen**: Schicht f√ºr Schicht komplexer\n",
    "- **Schicht 1**: Kanten, Linien, Farben\n",
    "- **Schicht 2**: Ecken, Kurven, Texturen\n",
    "- **Schicht 3+**: Objektteile, dann ganze Objekte\n",
    "- **Transfer Learning**: Nutze gelernte Features f√ºr neue Aufgaben\n",
    "- **Nat√ºrlich**: √Ñhnlich wie menschliche Wahrnehmung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79a10494e39ba30",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## In der n√§chsten Lektion\n",
    "\n",
    "- Praktisches Beispiel: MNIST-Ziffernerkennung\n",
    "- Training eines einfachen CNNs (mit sklearn)\n",
    "- Vergleich mit normalen Netzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e03423667dbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "lang,tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
