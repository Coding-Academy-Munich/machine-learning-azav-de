{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ecf2c6ad89b7f3",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "<img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRw\n",
    "Oi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMTExLjE2MSIgaGVpZ2h0PSIxMzQuNjY4\n",
    "IiB2ZXJzaW9uPSIxLjAiPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYyI+PHN0b3Agb2Zmc2V0\n",
    "PSIwIiBzdHlsZT0ic3RvcC1jb2xvcjojYjhiOGI4O3N0b3Atb3BhY2l0eTouNDk4MDM5MjIiLz48\n",
    "c3RvcCBvZmZzZXQ9IjEiIHN0eWxlPSJzdG9wLWNvbG9yOiM3ZjdmN2Y7c3RvcC1vcGFjaXR5OjAi\n",
    "Lz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYSI+PHN0b3Agb2Zmc2V0PSIw\n",
    "IiBzdHlsZT0ic3RvcC1jb2xvcjojZmZkNDNiO3N0b3Atb3BhY2l0eToxIi8+PHN0b3Agb2Zmc2V0\n",
    "PSIxIiBzdHlsZT0ic3RvcC1jb2xvcjojZmZlODczO3N0b3Atb3BhY2l0eToxIi8+PC9saW5lYXJH\n",
    "cmFkaWVudD48bGluZWFyR3JhZGllbnQgaWQ9ImIiPjxzdG9wIG9mZnNldD0iMCIgc3R5bGU9InN0\n",
    "b3AtY29sb3I6IzVhOWZkNDtzdG9wLW9wYWNpdHk6MSIvPjxzdG9wIG9mZnNldD0iMSIgc3R5bGU9\n",
    "InN0b3AtY29sb3I6IzMwNjk5ODtzdG9wLW9wYWNpdHk6MSIvPjwvbGluZWFyR3JhZGllbnQ+PGxp\n",
    "bmVhckdyYWRpZW50IHhsaW5rOmhyZWY9IiNhIiBpZD0iZSIgeDE9IjE1MC45NjEiIHgyPSIxMTIu\n",
    "MDMxIiB5MT0iMTkyLjM1MiIgeTI9IjEzNy4yNzMiIGdyYWRpZW50VHJhbnNmb3JtPSJtYXRyaXgo\n",
    "LjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRVbml0cz0idXNlclNw\n",
    "YWNlT25Vc2UiLz48bGluZWFyR3JhZGllbnQgeGxpbms6aHJlZj0iI2IiIGlkPSJkIiB4MT0iMjYu\n",
    "NjQ5IiB4Mj0iMTM1LjY2NSIgeTE9IjIwLjYwNCIgeTI9IjExNC4zOTgiIGdyYWRpZW50VHJhbnNm\n",
    "b3JtPSJtYXRyaXgoLjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRV\n",
    "bml0cz0idXNlclNwYWNlT25Vc2UiLz48cmFkaWFsR3JhZGllbnQgeGxpbms6aHJlZj0iI2MiIGlk\n",
    "PSJmIiBjeD0iNjEuNTE5IiBjeT0iMTMyLjI4NiIgcj0iMjkuMDM3IiBmeD0iNjEuNTE5IiBmeT0i\n",
    "MTMyLjI4NiIgZ3JhZGllbnRUcmFuc2Zvcm09Im1hdHJpeCgwIC0uMjM5OTUgMS4wNTQ2NyAwIC04\n",
    "My43IDE0Mi40NjIpIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIvPjwvZGVmcz48cGF0\n",
    "aCBkPSJNNTQuOTE5IDBjLTQuNTg0LjAyMi04Ljk2MS40MTMtMTIuODEzIDEuMDk1QzMwLjc2IDMu\n",
    "MDk5IDI4LjcgNy4yOTUgMjguNyAxNS4wMzJ2MTAuMjE5aDI2LjgxM3YzLjQwNkgxOC42MzhjLTcu\n",
    "NzkzIDAtMTQuNjE2IDQuNjg0LTE2Ljc1IDEzLjU5NC0yLjQ2MiAxMC4yMTMtMi41NzEgMTYuNTg2\n",
    "IDAgMjcuMjUgMS45MDUgNy45MzggNi40NTcgMTMuNTk0IDE0LjI1IDEzLjU5NGg5LjIxOHYtMTIu\n",
    "MjVjMC04Ljg1IDcuNjU3LTE2LjY1NyAxNi43NS0xNi42NTdoMjYuNzgyYzcuNDU0IDAgMTMuNDA2\n",
    "LTYuMTM4IDEzLjQwNi0xMy42MjV2LTI1LjUzYzAtNy4yNjctNi4xMy0xMi43MjYtMTMuNDA2LTEz\n",
    "LjkzOEM2NC4yODIuMzI4IDU5LjUwMi0uMDIgNTQuOTE4IDBtLTE0LjUgOC4yMmMyLjc3IDAgNS4w\n",
    "MzEgMi4yOTggNS4wMzEgNS4xMjUgMCAyLjgxNi0yLjI2MiA1LjA5My01LjAzMSA1LjA5My0yLjc4\n",
    "IDAtNS4wMzEtMi4yNzctNS4wMzEtNS4wOTMgMC0yLjgyNyAyLjI1MS01LjEyNSA1LjAzLTUuMTI1\n",
    "IiBzdHlsZT0iZmlsbDp1cmwoI2QpO2ZpbGwtb3BhY2l0eToxIi8+PHBhdGggZD0iTTg1LjYzOCAy\n",
    "OC42NTd2MTEuOTA2YzAgOS4yMzEtNy44MjYgMTctMTYuNzUgMTdINDIuMTA2Yy03LjMzNiAwLTEz\n",
    "LjQwNiA2LjI3OS0xMy40MDYgMTMuNjI1Vjk2LjcyYzAgNy4yNjYgNi4zMTkgMTEuNTQgMTMuNDA2\n",
    "IDEzLjYyNSA4LjQ4OCAyLjQ5NSAxNi42MjcgMi45NDYgMjYuNzgyIDAgNi43NS0xLjk1NSAxMy40\n",
    "MDYtNS44ODggMTMuNDA2LTEzLjYyNVY4Ni41SDU1LjUxM3YtMy40MDVIOTUuN2M3Ljc5MyAwIDEw\n",
    "LjY5Ni01LjQzNiAxMy40MDYtMTMuNTk0IDIuOC04LjM5OSAyLjY4LTE2LjQ3NiAwLTI3LjI1LTEu\n",
    "OTI1LTcuNzU4LTUuNjA0LTEzLjU5NC0xMy40MDYtMTMuNTk0ek03MC41NzUgOTMuMzEzYzIuNzgg\n",
    "MCA1LjAzMSAyLjI3OCA1LjAzMSA1LjA5NCAwIDIuODI3LTIuMjUxIDUuMTI1LTUuMDMxIDUuMTI1\n",
    "LTIuNzcgMC01LjAzMS0yLjI5OC01LjAzMS01LjEyNSAwLTIuODE2IDIuMjYxLTUuMDk0IDUuMDMx\n",
    "LTUuMDk0IiBzdHlsZT0iZmlsbDp1cmwoI2UpO2ZpbGwtb3BhY2l0eToxIi8+PGVsbGlwc2UgY3g9\n",
    "IjU1LjgxNyIgY3k9IjEyNy43MDEiIHJ4PSIzNS45MzEiIHJ5PSI2Ljk2NyIgc3R5bGU9Im9wYWNp\n",
    "dHk6LjQ0MzgyO2ZpbGw6dXJsKCNmKTtmaWxsLW9wYWNpdHk6MTtmaWxsLXJ1bGU6bm9uemVybztz\n",
    "dHJva2U6bm9uZTtzdHJva2Utd2lkdGg6MTUuNDE3NDtzdHJva2UtbWl0ZXJsaW1pdDo0O3N0cm9r\n",
    "ZS1kYXNoYXJyYXk6bm9uZTtzdHJva2Utb3BhY2l0eToxIi8+PC9zdmc+\n",
    "\"\n",
    "     style=\"display:block;margin:auto;width:10%\" alt=\"Python Logo\"/>\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align:center; font-size:200%;\">\n",
    " <b>Gradientenabstieg</b>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"text-align:center;\">Dr. Matthias Hölzl</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a8a5a980e3b44e",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Die große Frage\n",
    "\n",
    "- Wir wissen: Das Netz minimiert den Fehler\n",
    "- Aber **wie genau** findet es die besten Parameter?\n",
    "- Die Antwort: **Gradientenabstieg** (Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678c25bddf73de5",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from nn_training_deep_dive_plots import (\n",
    "    plot_simple_loss_landscape, plot_gradient_descent_steps,\n",
    "    plot_2d_loss_landscape, plot_2d_loss_landscape_3d,\n",
    "    plot_local_minimum, plot_different_starting_points,\n",
    "    plot_learning_rates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd3d6249a7a8c3",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a97332ae3ce9f9",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Eine Analogie: Abstieg vom Berg\n",
    "\n",
    "- Stellen Sie sich vor, Sie stehen auf einem Berg\n",
    "- Es ist neblig, Sie können nur wenige Meter weit sehen\n",
    "- Ihr Ziel: Ins Tal hinabsteigen\n",
    "- Wie finden Sie den Weg?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e5513c4b6686eb",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Die Strategie\n",
    "\n",
    "1. Schauen Sie sich um (im Nebel)\n",
    "2. Finden Sie die steilste Stelle nach unten\n",
    "3. Machen Sie einen Schritt in diese Richtung\n",
    "4. Wiederholen Sie, bis Sie im Tal sind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5b46d32dd09680",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Gradientenabstieg funktioniert genauso!\n",
    "\n",
    "- **Berg** = Loss-Funktion (Fehler)\n",
    "- **Tal** = Minimaler Fehler (bestes Modell)\n",
    "- **Steilste Stelle** = Gradient\n",
    "- **Schritt** = Parameter-Update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1238755935c729",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Visualisierung: Einfache Fehler-Landschaft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd6ca94a5bc7d4a",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a simple 1D loss function (parabola)\n",
    "w = np.linspace(-5, 5, 100)\n",
    "loss = (w - 2) ** 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4714faae2f3306",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdbbfac458a78492",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Schrittweises Abstieg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627b59e15c79a21",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Simulate gradient descent on the simple function\n",
    "def gradient_simple(w):\n",
    "    \"\"\"Gradient of (w-2)^2 + 1\"\"\"\n",
    "    return 2 * (w - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06c0205806bdb0e",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Gradient descent simulation\n",
    "w_start = -4\n",
    "learning_rate = 0.3\n",
    "steps = 15\n",
    "\n",
    "w_history = [w_start]\n",
    "loss_history = [(w_start - 2) ** 2 + 1]\n",
    "\n",
    "w_current = w_start\n",
    "for _ in range(steps):\n",
    "    grad = gradient_simple(w_current)\n",
    "    w_current = w_current - learning_rate * grad\n",
    "    w_history.append(w_current)\n",
    "    loss_history.append((w_current - 2) ** 2 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87306d7060b48a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b213c516ee69b262",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Was ist der Gradient?\n",
    "\n",
    "- Der **Gradient** ist die Steigung der Fehler-Funktion\n",
    "- Er zeigt in die Richtung des steilsten **Anstiegs**\n",
    "- Wir gehen in die **entgegengesetzte** Richtung (bergab)\n",
    "- Mathematisch: Eine Ableitung (oder mehrere bei vielen Parametern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169e9e5512663d5",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## 2D-Beispiel: Zwei Parameter\n",
    "\n",
    "- Neuronale Netze haben viele Parameter\n",
    "- Schauen wir uns zwei Parameter an\n",
    "- Die Fehler-Landschaft wird zu einem Gebirge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b87a008bb7a98f",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a 2D loss landscape\n",
    "w1_range = np.linspace(-3, 3, 100)\n",
    "w2_range = np.linspace(-3, 3, 100)\n",
    "W1, W2 = np.meshgrid(w1_range, w2_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320e42840152bbd0",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Simple bowl-shaped loss function\n",
    "Loss_2d = (W1 - 1) ** 2 + (W2 + 0.5) ** 2 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ee96265aac369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa1913e000c6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f8b37c2d9276fd6",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Das Problem: Lokale Minima\n",
    "\n",
    "- Unsere Analogie hat einen Haken!\n",
    "- Was passiert, wenn es mehrere Täler gibt?\n",
    "- Sie könnten in einem kleinen Tal landen, nicht im tiefsten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20e55264ceeacaa",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Beispiel: Der Funtensee\n",
    "\n",
    "- Der Funtensee liegt in den Berchtesgadener Alpen\n",
    "- Es ist ein Tal, das von höheren Bergen umgeben ist\n",
    "- Kältester Ort Deutschlands (kalte Luft sammelt sich)\n",
    "- Wenn Sie dort landen, denken Sie vielleicht, Sie sind am tiefsten Punkt\n",
    "- Aber es gibt tiefere Täler woanders!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00442759d5d844a",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a loss landscape with local minimum (like Funtensee)\n",
    "w_landscape = np.linspace(-5, 5, 200)\n",
    "# Create two valleys using negative Gaussians\n",
    "# Local valley (Funtensee) at w=-2 (shallower)\n",
    "# Global valley at w=3 (deeper)\n",
    "valley_local = -2.0 * np.exp(-((w_landscape + 2) ** 2) / 1.0)\n",
    "valley_global = -3.0 * np.exp(-((w_landscape - 3) ** 2) / 1.5)\n",
    "# Add baseline to keep all values positive\n",
    "loss_with_local = 5.5 + valley_local + valley_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a1c1952666b61",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b3c3cafe9ac2c56",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Lokales vs. Globales Minimum\n",
    "\n",
    "- **Lokales Minimum**: Ein Tal, aber nicht das tiefste\n",
    "- **Globales Minimum**: Das tiefste Tal überhaupt\n",
    "- Problem: Gradient Descent kann in lokalem Minimum stecken bleiben\n",
    "- Wie der Funtensee: Ein Tal, aber nicht das tiefste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6956caad5e3acdc2",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Demonstration: Wo man startet, ist wichtig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a836a49c26d058b4",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Gradient for the landscape with local minimum\n",
    "def gradient_landscape(w):\n",
    "    \"\"\"Numerical gradient of the loss landscape\"\"\"\n",
    "    h = 0.01\n",
    "    w_idx = np.argmin(np.abs(w_landscape - w))\n",
    "    if w_idx == 0 or w_idx == len(w_landscape) - 1:\n",
    "        return 0\n",
    "    return (loss_with_local[w_idx + 1] - loss_with_local[w_idx - 1]) / (2 * h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f56a318f154358",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Two different starting points\n",
    "def run_gradient_descent(w_start, learning_rate=0.1, steps=100):\n",
    "    \"\"\"Run gradient descent from a starting point\"\"\"\n",
    "    w_history = [w_start]\n",
    "    w_current = w_start\n",
    "\n",
    "    for _ in range(steps):\n",
    "        grad = gradient_landscape(w_current)\n",
    "        w_current = w_current - learning_rate * grad\n",
    "        w_history.append(w_current)\n",
    "\n",
    "    return w_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d489d2aa790f8a",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Start from left side (will reach Funtensee)\n",
    "path_left = run_gradient_descent(-4.0, learning_rate=0.05, steps=100)\n",
    "\n",
    "# Start from right side (will reach global minimum)\n",
    "path_right = run_gradient_descent(4.5, learning_rate=0.05, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d920c5bd13b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b903d11faf8bd48e",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Die Lernrate\n",
    "\n",
    "- Wie groß soll der Schritt sein?\n",
    "- Die **Lernrate** (Learning Rate) steuert die Schrittgröße\n",
    "- Zu groß: Man springt über das Minimum hinweg\n",
    "- Zu klein: Man braucht sehr lange\n",
    "- Genau richtig: Effizientes Lernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9243b04fb8464",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Demonstrate different learning rates\n",
    "path_small = run_gradient_descent(-4.0, learning_rate=0.01, steps=100)\n",
    "path_good = run_gradient_descent(-4.0, learning_rate=0.05, steps=100)\n",
    "path_large = run_gradient_descent(-4.0, learning_rate=0.2, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8771b5617d43e986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "598eef3ac4f3fc4b",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## In der Praxis\n",
    "\n",
    "- Neuronale Netze haben Hunderte oder Tausende von Parametern\n",
    "- Der Gradient zeigt für jeden Parameter die Richtung\n",
    "- Moderne Optimierer (wie Adam) passen die Lernrate automatisch an\n",
    "- Sie helfen, lokale Minima zu vermeiden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50dadb9d6e4a9d9",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Zusammenfassung\n",
    "\n",
    "- **Gradientenabstieg** = Methode zum Finden des Minimums\n",
    "- **Gradient** = Richtung des steilsten Anstiegs\n",
    "- Wir gehen in die entgegengesetzte Richtung (bergab)\n",
    "- **Lernrate** steuert die Schrittgröße\n",
    "- **Lokale Minima** wie der Funtensee sind ein Problem\n",
    "- Moderne Optimierer helfen, gute Lösungen zu finden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbb484299a35f9a",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## In der nächsten Lektion\n",
    "\n",
    "- Wie wir das in der Praxis anwenden\n",
    "- Epochen, Batches, und mehr\n",
    "- Praktische Tipps für das Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e03423667dbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,lang,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
