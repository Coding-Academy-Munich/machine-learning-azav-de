{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07114269317c254a",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "<img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRw\n",
    "Oi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMTExLjE2MSIgaGVpZ2h0PSIxMzQuNjY4\n",
    "IiB2ZXJzaW9uPSIxLjAiPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYyI+PHN0b3Agb2Zmc2V0\n",
    "PSIwIiBzdHlsZT0ic3RvcC1jb2xvcjojYjhiOGI4O3N0b3Atb3BhY2l0eTouNDk4MDM5MjIiLz48\n",
    "c3RvcCBvZmZzZXQ9IjEiIHN0eWxlPSJzdG9wLWNvbG9yOiM3ZjdmN2Y7c3RvcC1vcGFjaXR5OjAi\n",
    "Lz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYSI+PHN0b3Agb2Zmc2V0PSIw\n",
    "IiBzdHlsZT0ic3RvcC1jb2xvcjojZmZkNDNiO3N0b3Atb3BhY2l0eToxIi8+PHN0b3Agb2Zmc2V0\n",
    "PSIxIiBzdHlsZT0ic3RvcC1jb2xvcjojZmZlODczO3N0b3Atb3BhY2l0eToxIi8+PC9saW5lYXJH\n",
    "cmFkaWVudD48bGluZWFyR3JhZGllbnQgaWQ9ImIiPjxzdG9wIG9mZnNldD0iMCIgc3R5bGU9InN0\n",
    "b3AtY29sb3I6IzVhOWZkNDtzdG9wLW9wYWNpdHk6MSIvPjxzdG9wIG9mZnNldD0iMSIgc3R5bGU9\n",
    "InN0b3AtY29sb3I6IzMwNjk5ODtzdG9wLW9wYWNpdHk6MSIvPjwvbGluZWFyR3JhZGllbnQ+PGxp\n",
    "bmVhckdyYWRpZW50IHhsaW5rOmhyZWY9IiNhIiBpZD0iZSIgeDE9IjE1MC45NjEiIHgyPSIxMTIu\n",
    "MDMxIiB5MT0iMTkyLjM1MiIgeTI9IjEzNy4yNzMiIGdyYWRpZW50VHJhbnNmb3JtPSJtYXRyaXgo\n",
    "LjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRVbml0cz0idXNlclNw\n",
    "YWNlT25Vc2UiLz48bGluZWFyR3JhZGllbnQgeGxpbms6aHJlZj0iI2IiIGlkPSJkIiB4MT0iMjYu\n",
    "NjQ5IiB4Mj0iMTM1LjY2NSIgeTE9IjIwLjYwNCIgeTI9IjExNC4zOTgiIGdyYWRpZW50VHJhbnNm\n",
    "b3JtPSJtYXRyaXgoLjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRV\n",
    "bml0cz0idXNlclNwYWNlT25Vc2UiLz48cmFkaWFsR3JhZGllbnQgeGxpbms6aHJlZj0iI2MiIGlk\n",
    "PSJmIiBjeD0iNjEuNTE5IiBjeT0iMTMyLjI4NiIgcj0iMjkuMDM3IiBmeD0iNjEuNTE5IiBmeT0i\n",
    "MTMyLjI4NiIgZ3JhZGllbnRUcmFuc2Zvcm09Im1hdHJpeCgwIC0uMjM5OTUgMS4wNTQ2NyAwIC04\n",
    "My43IDE0Mi40NjIpIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIvPjwvZGVmcz48cGF0\n",
    "aCBkPSJNNTQuOTE5IDBjLTQuNTg0LjAyMi04Ljk2MS40MTMtMTIuODEzIDEuMDk1QzMwLjc2IDMu\n",
    "MDk5IDI4LjcgNy4yOTUgMjguNyAxNS4wMzJ2MTAuMjE5aDI2LjgxM3YzLjQwNkgxOC42MzhjLTcu\n",
    "NzkzIDAtMTQuNjE2IDQuNjg0LTE2Ljc1IDEzLjU5NC0yLjQ2MiAxMC4yMTMtMi41NzEgMTYuNTg2\n",
    "IDAgMjcuMjUgMS45MDUgNy45MzggNi40NTcgMTMuNTk0IDE0LjI1IDEzLjU5NGg5LjIxOHYtMTIu\n",
    "MjVjMC04Ljg1IDcuNjU3LTE2LjY1NyAxNi43NS0xNi42NTdoMjYuNzgyYzcuNDU0IDAgMTMuNDA2\n",
    "LTYuMTM4IDEzLjQwNi0xMy42MjV2LTI1LjUzYzAtNy4yNjctNi4xMy0xMi43MjYtMTMuNDA2LTEz\n",
    "LjkzOEM2NC4yODIuMzI4IDU5LjUwMi0uMDIgNTQuOTE4IDBtLTE0LjUgOC4yMmMyLjc3IDAgNS4w\n",
    "MzEgMi4yOTggNS4wMzEgNS4xMjUgMCAyLjgxNi0yLjI2MiA1LjA5My01LjAzMSA1LjA5My0yLjc4\n",
    "IDAtNS4wMzEtMi4yNzctNS4wMzEtNS4wOTMgMC0yLjgyNyAyLjI1MS01LjEyNSA1LjAzLTUuMTI1\n",
    "IiBzdHlsZT0iZmlsbDp1cmwoI2QpO2ZpbGwtb3BhY2l0eToxIi8+PHBhdGggZD0iTTg1LjYzOCAy\n",
    "OC42NTd2MTEuOTA2YzAgOS4yMzEtNy44MjYgMTctMTYuNzUgMTdINDIuMTA2Yy03LjMzNiAwLTEz\n",
    "LjQwNiA2LjI3OS0xMy40MDYgMTMuNjI1Vjk2LjcyYzAgNy4yNjYgNi4zMTkgMTEuNTQgMTMuNDA2\n",
    "IDEzLjYyNSA4LjQ4OCAyLjQ5NSAxNi42MjcgMi45NDYgMjYuNzgyIDAgNi43NS0xLjk1NSAxMy40\n",
    "MDYtNS44ODggMTMuNDA2LTEzLjYyNVY4Ni41SDU1LjUxM3YtMy40MDVIOTUuN2M3Ljc5MyAwIDEw\n",
    "LjY5Ni01LjQzNiAxMy40MDYtMTMuNTk0IDIuOC04LjM5OSAyLjY4LTE2LjQ3NiAwLTI3LjI1LTEu\n",
    "OTI1LTcuNzU4LTUuNjA0LTEzLjU5NC0xMy40MDYtMTMuNTk0ek03MC41NzUgOTMuMzEzYzIuNzgg\n",
    "MCA1LjAzMSAyLjI3OCA1LjAzMSA1LjA5NCAwIDIuODI3LTIuMjUxIDUuMTI1LTUuMDMxIDUuMTI1\n",
    "LTIuNzcgMC01LjAzMS0yLjI5OC01LjAzMS01LjEyNSAwLTIuODE2IDIuMjYxLTUuMDk0IDUuMDMx\n",
    "LTUuMDk0IiBzdHlsZT0iZmlsbDp1cmwoI2UpO2ZpbGwtb3BhY2l0eToxIi8+PGVsbGlwc2UgY3g9\n",
    "IjU1LjgxNyIgY3k9IjEyNy43MDEiIHJ4PSIzNS45MzEiIHJ5PSI2Ljk2NyIgc3R5bGU9Im9wYWNp\n",
    "dHk6LjQ0MzgyO2ZpbGw6dXJsKCNmKTtmaWxsLW9wYWNpdHk6MTtmaWxsLXJ1bGU6bm9uemVybztz\n",
    "dHJva2U6bm9uZTtzdHJva2Utd2lkdGg6MTUuNDE3NDtzdHJva2UtbWl0ZXJsaW1pdDo0O3N0cm9r\n",
    "ZS1kYXNoYXJyYXk6bm9uZTtzdHJva2Utb3BhY2l0eToxIi8+PC9zdmc+\n",
    "\"\n",
    "     style=\"display:block;margin:auto;width:10%\" alt=\"Python Logo\"/>\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align:center; font-size:200%;\">\n",
    " <b>Convolutional Neural Networks</b>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"text-align:center;\">Dr. Matthias Hölzl</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d777b4e5f2114af",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Das Problem mit normalen Netzen\n",
    "\n",
    "- Bilder haben sehr viele Pixel (Features)\n",
    "- 28×28 Bild = 784 Features\n",
    "- 224×224×3 Bild = 150.528 Features!\n",
    "- Standard-Netze (MLP) brauchen extrem viele Parameter\n",
    "- Wir brauchen eine bessere Lösung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54145f87ad96e138",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_digits\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd3d6249a7a8c3",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168b3d27a36af9e",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Die Lösung: Convolutional Neural Networks (CNNs)\n",
    "\n",
    "- **Spezielle Netze für Bilder**\n",
    "- Nutzen die Struktur von Bildern aus\n",
    "- Weniger Parameter als normale Netze\n",
    "- Erkennen **lokale Muster**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0884530d6d95951",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Kernidee: Filter (Kernel)\n",
    "\n",
    "- Ein **Filter** ist ein kleines Muster (z.B. 3×3)\n",
    "- Dieser Filter wird über das Bild geschoben\n",
    "- An jeder Position: Berechne eine Zahl\n",
    "- Das Ergebnis: Eine \"Feature Map\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b35505aa63845d",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Beispiel-Filter: Kanten-Detektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde9c532ec4726bf",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a simple vertical edge detector filter\n",
    "vertical_edge_filter = np.array([\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e2adb038278fb7",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a horizontal edge detector filter\n",
    "horizontal_edge_filter = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [ 0,  0,  0],\n",
    "    [ 1,  1,  1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6af64e337c22c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d48e7ee179d000d1",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Wie funktioniert ein Filter?\n",
    "\n",
    "- Filter wird über Bild geschoben\n",
    "- An jeder Position: **Element-weise Multiplikation**\n",
    "- Ergebnisse werden summiert\n",
    "- Das ergibt einen Wert in der Feature Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced710ea4f5148d",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Visualisierung der Faltung (Convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95885d6626364037",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Load a digit for demonstration\n",
    "digits = load_digits()\n",
    "sample_digit = digits.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5813f8869fda73",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def apply_convolution(image, kernel):\n",
    "    \"\"\"Apply convolution to image\"\"\"\n",
    "    # Use scipy's convolve2d for demonstration\n",
    "    return signal.convolve2d(image, kernel, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73305027c1f92b14",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Apply filters\n",
    "vertical_features = apply_convolution(sample_digit, vertical_edge_filter)\n",
    "horizontal_features = apply_convolution(sample_digit, horizontal_edge_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011df6da2e5e712",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_filter_application(original, filtered_v, filtered_h):\n",
    "    \"\"\"Plot original image and filtered results\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Original\n",
    "    axes[0].imshow(original, cmap='gray')\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Vertical edges\n",
    "    axes[1].imshow(vertical_features, cmap='gray')\n",
    "    axes[1].set_title('Vertical Edges Detected')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Horizontal edges\n",
    "    axes[2].imshow(horizontal_features, cmap='gray')\n",
    "    axes[2].set_title('Horizontal Edges Detected')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c4ff7c88aa732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2aeb90f79901effe",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Was passiert hier?\n",
    "\n",
    "- **Vertikaler Filter**: Erkennt vertikale Kanten\n",
    "- **Horizontaler Filter**: Erkennt horizontale Kanten\n",
    "- Jeder Filter spezialisiert sich auf ein Muster\n",
    "- CNNs **lernen** diese Filter automatisch!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5273e3912b33b7",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Mehrere Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda2c2a44ce56a37",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Create more filters\n",
    "diagonal_filter_1 = np.array([\n",
    "    [-1, 0, 0],\n",
    "    [ 0, 1, 0],\n",
    "    [ 0, 0, 1]\n",
    "])\n",
    "\n",
    "diagonal_filter_2 = np.array([\n",
    "    [ 0, 0, -1],\n",
    "    [ 0, 1,  0],\n",
    "    [ 1, 0,  0]\n",
    "])\n",
    "\n",
    "blur_filter = np.ones((3, 3)) / 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5402682081596",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Apply all filters\n",
    "diag1_features = apply_convolution(sample_digit, diagonal_filter_1)\n",
    "diag2_features = apply_convolution(sample_digit, diagonal_filter_2)\n",
    "blur_features = apply_convolution(sample_digit, blur_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c835d079b0dc7",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_multiple_filters(original):\n",
    "    \"\"\"Plot results of multiple filters\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "    # Original (twice)\n",
    "    axes[0, 0].imshow(original, cmap='gray')\n",
    "    axes[0, 0].set_title('Original')\n",
    "    axes[0, 0].axis('off')\n",
    "\n",
    "    # Vertical edges\n",
    "    axes[0, 1].imshow(vertical_features, cmap='gray')\n",
    "    axes[0, 1].set_title('Vertical Edges')\n",
    "    axes[0, 1].axis('off')\n",
    "\n",
    "    # Horizontal edges\n",
    "    axes[0, 2].imshow(horizontal_features, cmap='gray')\n",
    "    axes[0, 2].set_title('Horizontal Edges')\n",
    "    axes[0, 2].axis('off')\n",
    "\n",
    "    # Diagonal 1\n",
    "    axes[1, 0].imshow(diag1_features, cmap='gray')\n",
    "    axes[1, 0].set_title('Diagonal Edges (\\\\)')\n",
    "    axes[1, 0].axis('off')\n",
    "\n",
    "    # Diagonal 2\n",
    "    axes[1, 1].imshow(diag2_features, cmap='gray')\n",
    "    axes[1, 1].set_title('Diagonal Edges (/)')\n",
    "    axes[1, 1].axis('off')\n",
    "\n",
    "    # Blur\n",
    "    axes[1, 2].imshow(blur_features, cmap='gray')\n",
    "    axes[1, 2].set_title('Blur (Average)')\n",
    "    axes[1, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b74894ee618757",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e3c591c31e214f9",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Pooling: Größe reduzieren\n",
    "\n",
    "- Nach Convolution: Bild ist immer noch groß\n",
    "- **Pooling** reduziert die Größe\n",
    "- Typisch: **Max Pooling**\n",
    "- Nimmt das Maximum aus einem kleinen Bereich (z.B. 2×2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bbf4abbca0eedd",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Max Pooling Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f73374d617ee4",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def max_pool_2d(image, pool_size=2):\n",
    "    \"\"\"Apply max pooling to image\"\"\"\n",
    "    h, w = image.shape\n",
    "    new_h = h // pool_size\n",
    "    new_w = w // pool_size\n",
    "\n",
    "    pooled = np.zeros((new_h, new_w))\n",
    "\n",
    "    for i in range(new_h):\n",
    "        for j in range(new_w):\n",
    "            pooled[i, j] = np.max(\n",
    "                image[i*pool_size:(i+1)*pool_size,\n",
    "                      j*pool_size:(j+1)*pool_size]\n",
    "            )\n",
    "\n",
    "    return pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d1d41422a1fe30",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Apply max pooling\n",
    "pooled_digit = max_pool_2d(sample_digit, pool_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae872d6732a454d5",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_pooling_effect(original, pooled):\n",
    "    \"\"\"Plot original and pooled images\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Original\n",
    "    axes[0].imshow(original, cmap='gray')\n",
    "    axes[0].set_title(f'Original ({original.shape[0]}×{original.shape[1]})')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Pooled\n",
    "    axes[1].imshow(pooled, cmap='gray')\n",
    "    axes[1].set_title(f'After Max Pooling ({pooled.shape[0]}×{pooled.shape[1]})')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19746ae6fd385e6a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23d118c66ea5b351",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Warum Pooling?\n",
    "\n",
    "- Reduziert die Anzahl der Parameter\n",
    "- Macht das Netz robuster gegenüber kleinen Verschiebungen\n",
    "- Behält die wichtigsten Informationen\n",
    "- Schnellere Berechnungen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47af5ee546939e1",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Aufbau eines CNN\n",
    "\n",
    "1. **Input**: Bild\n",
    "2. **Convolutional Layer**: Mehrere Filter anwenden\n",
    "3. **Activation**: ReLU (wie bei normalen Netzen)\n",
    "4. **Pooling**: Größe reduzieren\n",
    "5. Wiederhole Schritte 2-4 mehrmals\n",
    "6. **Flatten**: Zu 1D-Array machen\n",
    "7. **Dense Layers**: Normale neuronale Netz-Schichten\n",
    "8. **Output**: Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b6fb9534f9d9b",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Visualisierung: CNN-Architektur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241678a04b88a8d0",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_cnn_architecture():\n",
    "    \"\"\"Plot simplified CNN architecture\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "    # Layer sizes for visualization\n",
    "    layers = [\n",
    "        {'name': 'Input\\n28×28×1', 'x': 1, 'size': 28, 'color': 'lightblue'},\n",
    "        {'name': 'Conv\\n26×26×32', 'x': 3, 'size': 26, 'color': 'lightcoral'},\n",
    "        {'name': 'Pool\\n13×13×32', 'x': 5, 'size': 13, 'color': 'lightgreen'},\n",
    "        {'name': 'Conv\\n11×11×64', 'x': 7, 'size': 11, 'color': 'lightcoral'},\n",
    "        {'name': 'Pool\\n5×5×64', 'x': 9, 'size': 5, 'color': 'lightgreen'},\n",
    "        {'name': 'Flatten\\n1600', 'x': 11, 'size': 3, 'color': 'lightyellow'},\n",
    "        {'name': 'Dense\\n10', 'x': 13, 'size': 1, 'color': 'lightgray'}\n",
    "    ]\n",
    "\n",
    "    for layer in layers:\n",
    "        # Draw rectangle representing layer\n",
    "        height = layer['size'] / 3  # Scale for visualization\n",
    "        rect = plt.Rectangle((layer['x'], 2.5 - height/2), 0.8, height,\n",
    "                            facecolor=layer['color'], edgecolor='black', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add layer name\n",
    "        ax.text(layer['x'] + 0.4, 1, layer['name'],\n",
    "               ha='center', va='top', fontsize=10, fontweight='bold')\n",
    "\n",
    "        # Draw arrows between layers\n",
    "        if layer['x'] < 13:\n",
    "            ax.arrow(layer['x'] + 0.9, 2.5, 0.9, 0,\n",
    "                    head_width=0.2, head_length=0.1, fc='black', ec='black')\n",
    "\n",
    "    ax.set_xlim(0, 14)\n",
    "    ax.set_ylim(0, 5)\n",
    "    ax.axis('off')\n",
    "    ax.set_title('CNN Architecture (Simplified)', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92499aabb823e88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81ad67d90dd6df54",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Parameter-Effizienz\n",
    "\n",
    "- **Normales Netz** auf 28×28 Bild:\n",
    "  - Input: 784 Features\n",
    "  - Hidden Layer (100 Neuronen): 78.400 Parameter!\n",
    "\n",
    "- **CNN** auf 28×28 Bild:\n",
    "  - Ein 3×3 Filter: Nur 9 Parameter\n",
    "  - 32 Filter: 32 × 9 = 288 Parameter\n",
    "  - Viel effizienter!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1900c3acaf89eaba",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Vorteile von CNNs\n",
    "\n",
    "- **Weniger Parameter** als normale Netze\n",
    "- **Erkennen lokale Muster** (Kanten, Texturen, etc.)\n",
    "- **Positions-invariant**: Erkennen Muster überall im Bild\n",
    "- **Hierarchisch**: Erste Layer → einfache Muster, tiefe Layer → komplexe Muster\n",
    "- **Sehr erfolgreich** für Bildverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b702f5f7adbfcf",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Zusammenfassung\n",
    "\n",
    "- **Convolution**: Filter werden über Bild geschoben\n",
    "- **Filter/Kernel**: Kleine Muster (z.B. 3×3), die Features erkennen\n",
    "- **Feature Maps**: Ergebnis der Convolution\n",
    "- **Pooling**: Reduziert Größe, behält wichtige Info\n",
    "- **CNN-Architektur**: Conv → Pool → Conv → Pool → Dense\n",
    "- **Vorteil**: Viel weniger Parameter als normale Netze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee2175f3970e51f",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## In der nächsten Lektion\n",
    "\n",
    "- Wie CNNs Schicht für Schicht lernen\n",
    "- Von Kanten über Formen zu Objekten\n",
    "- Visualisierung dessen, was CNNs \"sehen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e03423667dbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "lang,tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
