{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f752e84a5bf048",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "<img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRw\n",
    "Oi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMTExLjE2MSIgaGVpZ2h0PSIxMzQuNjY4\n",
    "IiB2ZXJzaW9uPSIxLjAiPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYyI+PHN0b3Agb2Zmc2V0\n",
    "PSIwIiBzdHlsZT0ic3RvcC1jb2xvcjojYjhiOGI4O3N0b3Atb3BhY2l0eTouNDk4MDM5MjIiLz48\n",
    "c3RvcCBvZmZzZXQ9IjEiIHN0eWxlPSJzdG9wLWNvbG9yOiM3ZjdmN2Y7c3RvcC1vcGFjaXR5OjAi\n",
    "Lz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYSI+PHN0b3Agb2Zmc2V0PSIw\n",
    "IiBzdHlsZT0ic3RvcC1jb2xvcjojZmZkNDNiO3N0b3Atb3BhY2l0eToxIi8+PHN0b3Agb2Zmc2V0\n",
    "PSIxIiBzdHlsZT0ic3RvcC1jb2xvcjojZmZlODczO3N0b3Atb3BhY2l0eToxIi8+PC9saW5lYXJH\n",
    "cmFkaWVudD48bGluZWFyR3JhZGllbnQgaWQ9ImIiPjxzdG9wIG9mZnNldD0iMCIgc3R5bGU9InN0\n",
    "b3AtY29sb3I6IzVhOWZkNDtzdG9wLW9wYWNpdHk6MSIvPjxzdG9wIG9mZnNldD0iMSIgc3R5bGU9\n",
    "InN0b3AtY29sb3I6IzMwNjk5ODtzdG9wLW9wYWNpdHk6MSIvPjwvbGluZWFyR3JhZGllbnQ+PGxp\n",
    "bmVhckdyYWRpZW50IHhsaW5rOmhyZWY9IiNhIiBpZD0iZSIgeDE9IjE1MC45NjEiIHgyPSIxMTIu\n",
    "MDMxIiB5MT0iMTkyLjM1MiIgeTI9IjEzNy4yNzMiIGdyYWRpZW50VHJhbnNmb3JtPSJtYXRyaXgo\n",
    "LjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRVbml0cz0idXNlclNw\n",
    "YWNlT25Vc2UiLz48bGluZWFyR3JhZGllbnQgeGxpbms6aHJlZj0iI2IiIGlkPSJkIiB4MT0iMjYu\n",
    "NjQ5IiB4Mj0iMTM1LjY2NSIgeTE9IjIwLjYwNCIgeTI9IjExNC4zOTgiIGdyYWRpZW50VHJhbnNm\n",
    "b3JtPSJtYXRyaXgoLjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRV\n",
    "bml0cz0idXNlclNwYWNlT25Vc2UiLz48cmFkaWFsR3JhZGllbnQgeGxpbms6aHJlZj0iI2MiIGlk\n",
    "PSJmIiBjeD0iNjEuNTE5IiBjeT0iMTMyLjI4NiIgcj0iMjkuMDM3IiBmeD0iNjEuNTE5IiBmeT0i\n",
    "MTMyLjI4NiIgZ3JhZGllbnRUcmFuc2Zvcm09Im1hdHJpeCgwIC0uMjM5OTUgMS4wNTQ2NyAwIC04\n",
    "My43IDE0Mi40NjIpIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIvPjwvZGVmcz48cGF0\n",
    "aCBkPSJNNTQuOTE5IDBjLTQuNTg0LjAyMi04Ljk2MS40MTMtMTIuODEzIDEuMDk1QzMwLjc2IDMu\n",
    "MDk5IDI4LjcgNy4yOTUgMjguNyAxNS4wMzJ2MTAuMjE5aDI2LjgxM3YzLjQwNkgxOC42MzhjLTcu\n",
    "NzkzIDAtMTQuNjE2IDQuNjg0LTE2Ljc1IDEzLjU5NC0yLjQ2MiAxMC4yMTMtMi41NzEgMTYuNTg2\n",
    "IDAgMjcuMjUgMS45MDUgNy45MzggNi40NTcgMTMuNTk0IDE0LjI1IDEzLjU5NGg5LjIxOHYtMTIu\n",
    "MjVjMC04Ljg1IDcuNjU3LTE2LjY1NyAxNi43NS0xNi42NTdoMjYuNzgyYzcuNDU0IDAgMTMuNDA2\n",
    "LTYuMTM4IDEzLjQwNi0xMy42MjV2LTI1LjUzYzAtNy4yNjctNi4xMy0xMi43MjYtMTMuNDA2LTEz\n",
    "LjkzOEM2NC4yODIuMzI4IDU5LjUwMi0uMDIgNTQuOTE4IDBtLTE0LjUgOC4yMmMyLjc3IDAgNS4w\n",
    "MzEgMi4yOTggNS4wMzEgNS4xMjUgMCAyLjgxNi0yLjI2MiA1LjA5My01LjAzMSA1LjA5My0yLjc4\n",
    "IDAtNS4wMzEtMi4yNzctNS4wMzEtNS4wOTMgMC0yLjgyNyAyLjI1MS01LjEyNSA1LjAzLTUuMTI1\n",
    "IiBzdHlsZT0iZmlsbDp1cmwoI2QpO2ZpbGwtb3BhY2l0eToxIi8+PHBhdGggZD0iTTg1LjYzOCAy\n",
    "OC42NTd2MTEuOTA2YzAgOS4yMzEtNy44MjYgMTctMTYuNzUgMTdINDIuMTA2Yy03LjMzNiAwLTEz\n",
    "LjQwNiA2LjI3OS0xMy40MDYgMTMuNjI1Vjk2LjcyYzAgNy4yNjYgNi4zMTkgMTEuNTQgMTMuNDA2\n",
    "IDEzLjYyNSA4LjQ4OCAyLjQ5NSAxNi42MjcgMi45NDYgMjYuNzgyIDAgNi43NS0xLjk1NSAxMy40\n",
    "MDYtNS44ODggMTMuNDA2LTEzLjYyNVY4Ni41SDU1LjUxM3YtMy40MDVIOTUuN2M3Ljc5MyAwIDEw\n",
    "LjY5Ni01LjQzNiAxMy40MDYtMTMuNTk0IDIuOC04LjM5OSAyLjY4LTE2LjQ3NiAwLTI3LjI1LTEu\n",
    "OTI1LTcuNzU4LTUuNjA0LTEzLjU5NC0xMy40MDYtMTMuNTk0ek03MC41NzUgOTMuMzEzYzIuNzgg\n",
    "MCA1LjAzMSAyLjI3OCA1LjAzMSA1LjA5NCAwIDIuODI3LTIuMjUxIDUuMTI1LTUuMDMxIDUuMTI1\n",
    "LTIuNzcgMC01LjAzMS0yLjI5OC01LjAzMS01LjEyNSAwLTIuODE2IDIuMjYxLTUuMDk0IDUuMDMx\n",
    "LTUuMDk0IiBzdHlsZT0iZmlsbDp1cmwoI2UpO2ZpbGwtb3BhY2l0eToxIi8+PGVsbGlwc2UgY3g9\n",
    "IjU1LjgxNyIgY3k9IjEyNy43MDEiIHJ4PSIzNS45MzEiIHJ5PSI2Ljk2NyIgc3R5bGU9Im9wYWNp\n",
    "dHk6LjQ0MzgyO2ZpbGw6dXJsKCNmKTtmaWxsLW9wYWNpdHk6MTtmaWxsLXJ1bGU6bm9uemVybztz\n",
    "dHJva2U6bm9uZTtzdHJva2Utd2lkdGg6MTUuNDE3NDtzdHJva2UtbWl0ZXJsaW1pdDo0O3N0cm9r\n",
    "ZS1kYXNoYXJyYXk6bm9uZTtzdHJva2Utb3BhY2l0eToxIi8+PC9zdmc+\n",
    "\"\n",
    "     style=\"display:block;margin:auto;width:10%\" alt=\"Python Logo\"/>\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align:center; font-size:200%;\">\n",
    " <b>Das Neuron</b>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"text-align:center;\">Dr. Matthias Hölzl</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9926972ceb6f7d49",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Unser lineares Modell - noch einmal betrachtet\n",
    "\n",
    "- Lineare Regression: $y = w_1 x_1 + w_2 x_2 + ... + w_n x_n + b$\n",
    "- Nimmt Features ($x_1, x_2, ...$)\n",
    "- Multipliziert sie mit Gewichten ($w_1, w_2, ...$)\n",
    "- Addiert einen Bias ($b$)\n",
    "- Gibt eine Vorhersage aus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b49591c442c6c62",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Das ist (fast schon) ein Neuron!\n",
    "\n",
    "- Ein künstliches Neuron funktioniert genauso\n",
    "- Es ist wie eine \"Entscheidungszelle\"\n",
    "- Nimmt Eingaben, verarbeitet sie, gibt eine Ausgabe\n",
    "- Aber..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2348417aad077ac",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Struktur eines Neurons\n",
    "\n",
    "<img src=\"img/neuron-structure.png\" alt=\"Neuron Structure\" style=\"width:50%;float:right;\">\n",
    "\n",
    "- **Eingaben**: Die Features (x₁, x₂, ...)\n",
    "- **Gewichte**: Wie wichtig ist jede Eingabe?\n",
    "- **Bias**: Ein Schwellenwert\n",
    "- **Ausgabe**: Das Ergebnis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1db74b19bf5e9fc",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Der wichtige Unterschied!\n",
    "\n",
    "- Bei linearer Regression: direkte Berechnung\n",
    "- Bei Neuronen: eine zusätzliche **Aktivierungsfunktion**\n",
    "- Diese Funktion macht Neuronen viel mächtiger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83200bf16ab1e6d3",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Was ist eine Aktivierungsfunktion?\n",
    "\n",
    "- Nach der gewichteten Summe\n",
    "- Wird das Ergebnis durch eine Funktion \"gefiltert\"\n",
    "- Diese Funktion entscheidet: \"Wie stark soll die Ausgabe sein?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de9236b8e018186",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Aktivierungsfunktion 1: Sigmoid\n",
    "\n",
    "- Wandelt jede Zahl in einen Wert zwischen 0 und 1 um\n",
    "- Wie ein **Dimmer-Schalter** für Licht\n",
    "- Sehr negative Zahlen → fast 0\n",
    "- Sehr positive Zahlen → fast 1\n",
    "- Zahlen um 0 → etwa 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ad4496dd347d5",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "Kurze Unterbrechung zum Installieren von Paketen..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15002ce3066021",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import install_packages  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0f725cab0b2213",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from plot_utils import (\n",
    "    plot_neuron_response,\n",
    "    plot_relu,\n",
    "    plot_sigmoid_vs_relu,\n",
    "    plot_sigmoid,\n",
    "    relu,\n",
    "    sigmoid,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1db1fcc6922a4c1",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Visualisierung der Sigmoid-Funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2aa5c332ab7af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df62fb91d5fdc3f4",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Warum ist das nützlich?\n",
    "\n",
    "- Begrenzt die Ausgabe\n",
    "- Glättet extreme Werte\n",
    "- Macht das Modell \"sanfter\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4431ec8aec6ee0bd",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Aktivierungsfunktion 2: ReLU\n",
    "\n",
    "- ReLU = **Re**ctified **L**inear **U**nit\n",
    "- Wie ein **Einwegventil**\n",
    "- Negative Zahlen → 0\n",
    "- Positive Zahlen → bleiben unverändert\n",
    "- Am häufigsten verwendet!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02438b8c84d438d7",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Visualisierung der ReLU-Funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60ce3486c6e6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07ebfbef7e4cc96b",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## ReLU: Einfach aber effektiv\n",
    "\n",
    "- Sehr schnell zu berechnen\n",
    "- Hilft beim Training großer Netze\n",
    "- Verhindert bestimmte Probleme beim Lernen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a91301014d332e",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Vergleich: Sigmoid vs ReLU\n",
    "\n",
    "- **Sigmoid**: Glatt, begrenzt, wie ein Dimmer\n",
    "- **ReLU**: Einfach, unbegrenzt für positive Werte, wie ein Ventil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90591a5cf8f4bdd8",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Vergleich der Aktivierungsfunktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee18733a93cbdc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45e5d00c429382b4",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Ein Neuron in Aktion\n",
    "\n",
    "- Schauen wir uns ein konkretes Beispiel an\n",
    "- Ein Neuron mit 2 Eingaben\n",
    "- ReLU Aktivierungsfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f67e8e863a6057",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def simple_neuron(x1, x2, w1=0.5, w2=-0.3, bias=1.0):\n",
    "    \"\"\"A simple neuron with 2 inputs and ReLU activation\"\"\"\n",
    "    # Weighted sum\n",
    "    z = w1 * x1 + w2 * x2 + bias\n",
    "    # Apply ReLU activation\n",
    "    output = relu(z)\n",
    "    return z, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8c257b2d87fedc",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Visualisierung der Neuron-Ausgabe\n",
    "\n",
    "- Wie reagiert das Neuron auf verschiedene Eingaben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1e41d2aef10c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ac7c11bb82acba9",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Warum Aktivierungsfunktionen wichtig sind\n",
    "\n",
    "- **Ohne** Aktivierungsfunktion: nur lineare Kombinationen möglich\n",
    "- **Mit** Aktivierungsfunktion: nichtlineare Muster möglich\n",
    "- Das ist der Schlüssel zur Flexibilität neuronaler Netze!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52d26d9df22fb38",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Demonstration: Mit vs. Ohne Aktivierung\n",
    "\n",
    "- Mehrere Neuronen ohne Aktivierung = immer noch linear\n",
    "- Mehrere Neuronen mit Aktivierung = nichtlinear!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5522841e85e2e25e",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Lineare Funktionen kombiniert bleiben linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f002b9092c665163",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from plot_utils import plot_combining_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89afa0c82c3db2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "242cd7dc51a63f85",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Mit Aktivierung wird es nichtlinear!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3830d13e1fb9ab3",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from plot_utils import plot_combining_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d3098af24af31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee5f8dc78dfc59da",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Zusammenfassung: Das Neuron\n",
    "\n",
    "- Ein Neuron = gewichtete Summe + Aktivierungsfunktion\n",
    "- Aktivierungsfunktionen ermöglichen Nichtlinearität\n",
    "- **Sigmoid**: wie ein Dimmer (0 bis 1)\n",
    "- **ReLU**: wie ein Ventil (0 oder positiv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdc6fe743f46777",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Nächster Schritt\n",
    "\n",
    "- Ein einzelnes Neuron ist noch begrenzt\n",
    "- Aber was ist, wenn wir viele Neuronen kombinieren?\n",
    "- Das machen wir in der nächsten Lektion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e03423667dbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "lang,tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
