{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d957492ee2ea4e4",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "<img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRw\n",
    "Oi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMTExLjE2MSIgaGVpZ2h0PSIxMzQuNjY4\n",
    "IiB2ZXJzaW9uPSIxLjAiPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYyI+PHN0b3Agb2Zmc2V0\n",
    "PSIwIiBzdHlsZT0ic3RvcC1jb2xvcjojYjhiOGI4O3N0b3Atb3BhY2l0eTouNDk4MDM5MjIiLz48\n",
    "c3RvcCBvZmZzZXQ9IjEiIHN0eWxlPSJzdG9wLWNvbG9yOiM3ZjdmN2Y7c3RvcC1vcGFjaXR5OjAi\n",
    "Lz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYSI+PHN0b3Agb2Zmc2V0PSIw\n",
    "IiBzdHlsZT0ic3RvcC1jb2xvcjojZmZkNDNiO3N0b3Atb3BhY2l0eToxIi8+PHN0b3Agb2Zmc2V0\n",
    "PSIxIiBzdHlsZT0ic3RvcC1jb2xvcjojZmZlODczO3N0b3Atb3BhY2l0eToxIi8+PC9saW5lYXJH\n",
    "cmFkaWVudD48bGluZWFyR3JhZGllbnQgaWQ9ImIiPjxzdG9wIG9mZnNldD0iMCIgc3R5bGU9InN0\n",
    "b3AtY29sb3I6IzVhOWZkNDtzdG9wLW9wYWNpdHk6MSIvPjxzdG9wIG9mZnNldD0iMSIgc3R5bGU9\n",
    "InN0b3AtY29sb3I6IzMwNjk5ODtzdG9wLW9wYWNpdHk6MSIvPjwvbGluZWFyR3JhZGllbnQ+PGxp\n",
    "bmVhckdyYWRpZW50IHhsaW5rOmhyZWY9IiNhIiBpZD0iZSIgeDE9IjE1MC45NjEiIHgyPSIxMTIu\n",
    "MDMxIiB5MT0iMTkyLjM1MiIgeTI9IjEzNy4yNzMiIGdyYWRpZW50VHJhbnNmb3JtPSJtYXRyaXgo\n",
    "LjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRVbml0cz0idXNlclNw\n",
    "YWNlT25Vc2UiLz48bGluZWFyR3JhZGllbnQgeGxpbms6aHJlZj0iI2IiIGlkPSJkIiB4MT0iMjYu\n",
    "NjQ5IiB4Mj0iMTM1LjY2NSIgeTE9IjIwLjYwNCIgeTI9IjExNC4zOTgiIGdyYWRpZW50VHJhbnNm\n",
    "b3JtPSJtYXRyaXgoLjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRV\n",
    "bml0cz0idXNlclNwYWNlT25Vc2UiLz48cmFkaWFsR3JhZGllbnQgeGxpbms6aHJlZj0iI2MiIGlk\n",
    "PSJmIiBjeD0iNjEuNTE5IiBjeT0iMTMyLjI4NiIgcj0iMjkuMDM3IiBmeD0iNjEuNTE5IiBmeT0i\n",
    "MTMyLjI4NiIgZ3JhZGllbnRUcmFuc2Zvcm09Im1hdHJpeCgwIC0uMjM5OTUgMS4wNTQ2NyAwIC04\n",
    "My43IDE0Mi40NjIpIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIvPjwvZGVmcz48cGF0\n",
    "aCBkPSJNNTQuOTE5IDBjLTQuNTg0LjAyMi04Ljk2MS40MTMtMTIuODEzIDEuMDk1QzMwLjc2IDMu\n",
    "MDk5IDI4LjcgNy4yOTUgMjguNyAxNS4wMzJ2MTAuMjE5aDI2LjgxM3YzLjQwNkgxOC42MzhjLTcu\n",
    "NzkzIDAtMTQuNjE2IDQuNjg0LTE2Ljc1IDEzLjU5NC0yLjQ2MiAxMC4yMTMtMi41NzEgMTYuNTg2\n",
    "IDAgMjcuMjUgMS45MDUgNy45MzggNi40NTcgMTMuNTk0IDE0LjI1IDEzLjU5NGg5LjIxOHYtMTIu\n",
    "MjVjMC04Ljg1IDcuNjU3LTE2LjY1NyAxNi43NS0xNi42NTdoMjYuNzgyYzcuNDU0IDAgMTMuNDA2\n",
    "LTYuMTM4IDEzLjQwNi0xMy42MjV2LTI1LjUzYzAtNy4yNjctNi4xMy0xMi43MjYtMTMuNDA2LTEz\n",
    "LjkzOEM2NC4yODIuMzI4IDU5LjUwMi0uMDIgNTQuOTE4IDBtLTE0LjUgOC4yMmMyLjc3IDAgNS4w\n",
    "MzEgMi4yOTggNS4wMzEgNS4xMjUgMCAyLjgxNi0yLjI2MiA1LjA5My01LjAzMSA1LjA5My0yLjc4\n",
    "IDAtNS4wMzEtMi4yNzctNS4wMzEtNS4wOTMgMC0yLjgyNyAyLjI1MS01LjEyNSA1LjAzLTUuMTI1\n",
    "IiBzdHlsZT0iZmlsbDp1cmwoI2QpO2ZpbGwtb3BhY2l0eToxIi8+PHBhdGggZD0iTTg1LjYzOCAy\n",
    "OC42NTd2MTEuOTA2YzAgOS4yMzEtNy44MjYgMTctMTYuNzUgMTdINDIuMTA2Yy03LjMzNiAwLTEz\n",
    "LjQwNiA2LjI3OS0xMy40MDYgMTMuNjI1Vjk2LjcyYzAgNy4yNjYgNi4zMTkgMTEuNTQgMTMuNDA2\n",
    "IDEzLjYyNSA4LjQ4OCAyLjQ5NSAxNi42MjcgMi45NDYgMjYuNzgyIDAgNi43NS0xLjk1NSAxMy40\n",
    "MDYtNS44ODggMTMuNDA2LTEzLjYyNVY4Ni41SDU1LjUxM3YtMy40MDVIOTUuN2M3Ljc5MyAwIDEw\n",
    "LjY5Ni01LjQzNiAxMy40MDYtMTMuNTk0IDIuOC04LjM5OSAyLjY4LTE2LjQ3NiAwLTI3LjI1LTEu\n",
    "OTI1LTcuNzU4LTUuNjA0LTEzLjU5NC0xMy40MDYtMTMuNTk0ek03MC41NzUgOTMuMzEzYzIuNzgg\n",
    "MCA1LjAzMSAyLjI3OCA1LjAzMSA1LjA5NCAwIDIuODI3LTIuMjUxIDUuMTI1LTUuMDMxIDUuMTI1\n",
    "LTIuNzcgMC01LjAzMS0yLjI5OC01LjAzMS01LjEyNSAwLTIuODE2IDIuMjYxLTUuMDk0IDUuMDMx\n",
    "LTUuMDk0IiBzdHlsZT0iZmlsbDp1cmwoI2UpO2ZpbGwtb3BhY2l0eToxIi8+PGVsbGlwc2UgY3g9\n",
    "IjU1LjgxNyIgY3k9IjEyNy43MDEiIHJ4PSIzNS45MzEiIHJ5PSI2Ljk2NyIgc3R5bGU9Im9wYWNp\n",
    "dHk6LjQ0MzgyO2ZpbGw6dXJsKCNmKTtmaWxsLW9wYWNpdHk6MTtmaWxsLXJ1bGU6bm9uemVybztz\n",
    "dHJva2U6bm9uZTtzdHJva2Utd2lkdGg6MTUuNDE3NDtzdHJva2UtbWl0ZXJsaW1pdDo0O3N0cm9r\n",
    "ZS1kYXNoYXJyYXk6bm9uZTtzdHJva2Utb3BhY2l0eToxIi8+PC9zdmc+\n",
    "\"\n",
    "     style=\"display:block;margin:auto;width:10%\" alt=\"Python Logo\"/>\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align:center; font-size:200%;\">\n",
    " <b>LangChain: Ein einfacher Chatbot</b>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"text-align:center;\">Dr. Matthias Hölzl</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8136c9a7880957",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Was wir bisher gebaut haben\n",
    "\n",
    "Mit `requests`/OpenAI API haben wir einen funktionierenden Chatbot erstellt:\n",
    "\n",
    "- `SimpleChatbot` Klasse mit `self.messages`\n",
    "- Konversationsverlauf wird gespeichert\n",
    "- System-Prompt für Persönlichkeit\n",
    "\n",
    "**Das funktioniert gut!** Aber..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0553ba6a320f80",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Verschiedene APIs\n",
    "\n",
    "Viele Anbieter nutzen OpenAI-kompatible APIs:\n",
    "\n",
    "- OpenRouter, Together AI, Groq, lokale Server (Ollama, vLLM)\n",
    "- Gleicher Code funktioniert mit verschiedenen Anbietern\n",
    "\n",
    "Aber nicht alle:\n",
    "\n",
    "- **Anthropic Claude** hat eine eigene API\n",
    "- Manche Anbieter haben spezielle Funktionen\n",
    "\n",
    "Außerdem: Direkte API-Aufrufe erfordern viel Boilerplate-Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074327c963c65394",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Die Lösung: LangChain\n",
    "\n",
    "- **Framework** für LLM-Anwendungen\n",
    "- **Einheitliche Schnittstelle** für alle Anbieter\n",
    "- Gleicher Code funktioniert mit OpenAI, Anthropic, lokalen Modellen...\n",
    "- **Industrie-Standard** (in 60%+ der Job-Anzeigen!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af695216da0540f",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24930085a379a8a8",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain-core langchain-openai langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4135f7cdf8859522",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce35827a2adb266e",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd46f8ffc84826ee",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Der einfachste LangChain-Aufruf\n",
    "\n",
    "Nur zwei Zeilen Code für OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230acfe8e4018705",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd1e07a64e01d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7336630ceb6ff624",
   "metadata": {
    "lang": "de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3adff1be2429a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a55cca2f396c8c6c",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Das Ergebnis verstehen\n",
    "\n",
    "- `llm.invoke()` gibt ein `AIMessage` Objekt zurück\n",
    "- `.content` enthält den Text der Antwort\n",
    "- Viel einfacher als mit `requests`!\n",
    "- `OPENAI_API_KEY` wird automatisch aus der Umgebung gelesen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f686af97d03928f",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Mit OpenRouter\n",
    "\n",
    "Für OpenRouter geben wir API-Key und Base-URL an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee58383d3500ebc0",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "model = \"mistralai/ministral-14b-2512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a361677462194",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64aec2384483600",
   "metadata": {
    "lang": "de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe92f73d941d94",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78731e3b16e9267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d742c6c6503b608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f230ea64b0a25530",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Nachrichtentypen in LangChain\n",
    "\n",
    "LangChain verwendet spezielle Klassen für Nachrichten:\n",
    "\n",
    "- `HumanMessage`: Nachricht vom Benutzer\n",
    "- `AIMessage`: Antwort vom LLM\n",
    "- `SystemMessage`: System-Prompt (Anweisungen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a532a8fff2ccd87c",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b934e7eab00443",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Nachrichten als Liste\n",
    "\n",
    "Genau wie bei der REST API können wir eine Liste von Nachrichten senden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c9ac4df132bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b6c6e46a55f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2db25d8257806b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "492488bfe290465d",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Unser LangChain-Chatbot\n",
    "\n",
    "Jetzt bauen wir einen Chatbot mit LangChain!\n",
    "\n",
    "Die Struktur ist **identisch** zu unserem `SimpleChatbot`:\n",
    "- `self.messages` speichert den Verlauf\n",
    "- `chat()` Methode für Konversation\n",
    "\n",
    "Aber: **Viel weniger Code!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b34e8a56ca5d3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2287ce2d70c1296b",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Den Chatbot testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21fcb1555d0544b",
   "metadata": {
    "lang": "de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd53d569ca8ef4",
   "metadata": {
    "lang": "de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a924b5c366049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a705da06dd92fc",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e424de5ac52b3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d0bef9fb75713",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53652248591614e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "533e11ed14209e9d",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Der Verlauf\n",
    "\n",
    "Unser Chatbot erinnert sich an alles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c7c746837670cd",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "for msg in bot.messages:\n",
    "    role = type(msg).__name__\n",
    "    content = msg.content[:60] + \"...\" if len(msg.content) > 60 else msg.content\n",
    "    print(f\"{role}: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decddfbacf0eef43",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Vorteil: Provider wechseln\n",
    "\n",
    "Mit einer kleinen Änderung können wir den Provider wechseln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c21b1c050e79551",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_core.language_models.base import BaseLanguageModel\n",
    "from langchain_anthropic import ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6926d31108803c53",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def create_llm(provider) -> BaseLanguageModel:\n",
    "    \"\"\"Create LLM based on provider name.\"\"\"\n",
    "    if provider == \"openrouter\":\n",
    "        return ChatOpenAI(\n",
    "            api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            model=model,\n",
    "        )\n",
    "    elif provider == \"openai\":\n",
    "        return ChatOpenAI(\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "            model=\"gpt-5.2\",\n",
    "        )\n",
    "    elif provider == \"anthropic\":\n",
    "        return ChatAnthropic(\n",
    "            api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "            model=\"claude-haiku-4-5\",\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown provider: {provider}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d7f493292b768c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "start",
     "subslide"
    ]
   },
   "outputs": [],
   "source": [
    "class FlexibleChatbot:\n",
    "    \"\"\"A chatbot that can use different providers.\"\"\"\n",
    "\n",
    "    def __init__(self, provider=\"openrouter\", system_prompt=None):\n",
    "        self.llm = ChatOpenAI(\n",
    "            api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            model=model,\n",
    "        )\n",
    "        self.messages = []\n",
    "        if system_prompt:\n",
    "            self.messages.append(SystemMessage(content=system_prompt))\n",
    "\n",
    "    def chat(self, user_message):\n",
    "        \"\"\"Send a message and get a response.\"\"\"\n",
    "        self.messages.append(HumanMessage(content=user_message))\n",
    "        response = self.llm.invoke(self.messages)\n",
    "        self.messages.append(response)\n",
    "        return response.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe45dce19015c3ca",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Verschiedene Provider testen\n",
    "\n",
    "Gleicher Code, verschiedene Modelle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6962f01145e813af",
   "metadata": {
    "lang": "de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e220e72b52bb605",
   "metadata": {
    "lang": "de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f192eba7b54fee9",
   "metadata": {
    "lang": "de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d1713a87ea0f9",
   "metadata": {
    "lang": "de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244a79736ca35a3",
   "metadata": {
    "lang": "de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c8d3b9c5e893e",
   "metadata": {
    "lang": "de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c0a33e629d4ae19",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Alternative: RunnableWithMessageHistory\n",
    "\n",
    "LangChain bietet auch `RunnableWithMessageHistory` für Session-basierte\n",
    "Konversationen:\n",
    "\n",
    "- Automatische Verwaltung des Nachrichtenverlaufs\n",
    "- Unterstützung für mehrere Sessions (z.B. verschiedene Benutzer)\n",
    "- Integration mit verschiedenen Speicher-Backends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c31dfdc0e74d3d5",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a3fe4f47830bec",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Aufbau eines Chatbots mit RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06caf24f9f8454",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5163fb685bc34",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def get_session_history(session_id) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e9bc5d5c4ccd4",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "chatbot_with_history = RunnableWithMessageHistory(llm, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002a5892d316322",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "session_id = \"user_123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58fce0517a38fab",
   "metadata": {
    "lang": "de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb4ad22d66128fe",
   "metadata": {
    "lang": "de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c55f339950d7d3d",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Der Verlauf wird automatisch verwaltet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a57f94ff3b82f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fef34e1924377221",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Zusammenfassung\n",
    "\n",
    "- **LangChain** abstrahiert verschiedene LLM-Anbieter\n",
    "- **Gleicher Code** funktioniert mit OpenAI, Anthropic, etc.\n",
    "- **Klassen-basierter Chatbot** mit `self.messages` (wie vorher)\n",
    "- **Nachrichtentypen**: `HumanMessage`, `AIMessage`, `SystemMessage`\n",
    "- **Provider-Wechsel** mit minimalen Änderungen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82f01bf1ffa2ca4",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Gradio-Chatbot mit System-Prompt\n",
    "\n",
    "Vorbereitung für den Workshop:\n",
    "- Wir bauen einen Chatbot mit wählbarem System-Prompt\n",
    "  - Im Notebook oder als eigenständige App: `Projekte/SimpleLangChainChatbot`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd696d413ec4acf",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Wie `additional_inputs` funktioniert\n",
    "\n",
    "`gr.ChatInterface` ruft unsere Funktion `fn` mit folgenden Parametern auf:\n",
    "\n",
    "1. `message` - Die aktuelle Benutzernachricht\n",
    "2. `history` - Die bisherige Konversation (Liste von Nachrichten)\n",
    "3. **Weitere Parameter** aus `additional_inputs` (in der gleichen Reihenfolge!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb39f40d2ba705e",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Beispiel\n",
    "\n",
    "```python\n",
    "additional_inputs=[\n",
    "    gr.Dropdown(...),  # → 3. Parameter\n",
    "    gr.Slider(...),    # → 4. Parameter\n",
    "]\n",
    "\n",
    "def fn(message, history, dropdown_value, slider_value):\n",
    "    ...\n",
    "```\n",
    "\n",
    "Die Reihenfolge in `additional_inputs` bestimmt die Reihenfolge der Parameter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5777c88c8865f5f3",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfbdae15f3d4d8e",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPTS = {\n",
    "    \"Helpful Assistant\": \"You are a helpful assistant.\",\n",
    "    \"Python Tutor\": \"You are a friendly Python tutor who explains concepts simply.\",\n",
    "    \"Pirate\": \"You are a pirate. Answer all questions like a pirate would.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4058bec845f8bd",
   "metadata": {
    "lines_to_next_cell": 1,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "start",
     "subslide"
    ]
   },
   "outputs": [],
   "source": [
    "def chat_with_system_prompt(message, history):\n",
    "    \"\"\"Chatbot that uses the selected system prompt.\"\"\"\n",
    "    system_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "    messages: list = [SystemMessage(content=system_prompt)]\n",
    "    for msg in history:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            messages.append(HumanMessage(content=msg[\"content\"]))\n",
    "        elif msg[\"role\"] == \"assistant\":\n",
    "            messages.append(AIMessage(content=msg[\"content\"]))\n",
    "    messages.append(HumanMessage(content=message))\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26767361389fd5fd",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "keep",
     "subslide"
    ]
   },
   "outputs": [],
   "source": [
    "system_prompt_demo = gr.ChatInterface(\n",
    "    fn=chat_with_system_prompt,\n",
    "    type=\"messages\",\n",
    "    additional_inputs=[\n",
    "        gr.Dropdown(\n",
    "            choices=list(SYSTEM_PROMPTS.keys()),\n",
    "            value=\"Helpful Assistant\",\n",
    "            label=\"System Prompt\",\n",
    "        ),\n",
    "    ],\n",
    "    title=\"Chatbot mit System-Prompt\",\n",
    "    description=\"Wählen Sie einen System-Prompt!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0128ee8ef0193470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e6b590ae0de01e9",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Workshop: Multi-Provider Chatbot\n",
    "\n",
    "**Ziel**: Einen Chatbot bauen, bei dem man den Provider wählen kann!\n",
    "\n",
    "**Aufgaben**:\n",
    "1. Erstellen Sie einen `FlexibleChatbot` mit Gradio-Interface\n",
    "2. Fügen Sie ein Dropdown hinzu, um den Provider zu wählen\n",
    "3. Testen Sie verschiedene Provider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d874db8e7d66ea9",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Teil 1: Chatbot-Funktion\n",
    "\n",
    "Wir brauchen eine Funktion, die mit Gradio funktioniert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e83c88be06ebb",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "chatbot_instances = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d9cb07e7b3b2c",
   "metadata": {
    "tags": [
     "start"
    ]
   },
   "outputs": [],
   "source": [
    "def multi_provider_chat(message, history, provider):\n",
    "    \"\"\"Chatbot that can switch providers.\"\"\"\n",
    "    # TODO: Implement chatbot that uses FlexibleChatbot\n",
    "    # Hint: Store chatbot instance in chatbot_instances dict\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248aa76a7e87fd14",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Teil 2: Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f5c4b779d5340c",
   "metadata": {
    "tags": [
     "start"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Create ChatInterface with provider dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9f2d664d01e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "lang,tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
