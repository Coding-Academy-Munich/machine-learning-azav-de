{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf5ca94dfb0b9bf9",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "<img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRw\n",
    "Oi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMTExLjE2MSIgaGVpZ2h0PSIxMzQuNjY4\n",
    "IiB2ZXJzaW9uPSIxLjAiPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYyI+PHN0b3Agb2Zmc2V0\n",
    "PSIwIiBzdHlsZT0ic3RvcC1jb2xvcjojYjhiOGI4O3N0b3Atb3BhY2l0eTouNDk4MDM5MjIiLz48\n",
    "c3RvcCBvZmZzZXQ9IjEiIHN0eWxlPSJzdG9wLWNvbG9yOiM3ZjdmN2Y7c3RvcC1vcGFjaXR5OjAi\n",
    "Lz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYSI+PHN0b3Agb2Zmc2V0PSIw\n",
    "IiBzdHlsZT0ic3RvcC1jb2xvcjojZmZkNDNiO3N0b3Atb3BhY2l0eToxIi8+PHN0b3Agb2Zmc2V0\n",
    "PSIxIiBzdHlsZT0ic3RvcC1jb2xvcjojZmZlODczO3N0b3Atb3BhY2l0eToxIi8+PC9saW5lYXJH\n",
    "cmFkaWVudD48bGluZWFyR3JhZGllbnQgaWQ9ImIiPjxzdG9wIG9mZnNldD0iMCIgc3R5bGU9InN0\n",
    "b3AtY29sb3I6IzVhOWZkNDtzdG9wLW9wYWNpdHk6MSIvPjxzdG9wIG9mZnNldD0iMSIgc3R5bGU9\n",
    "InN0b3AtY29sb3I6IzMwNjk5ODtzdG9wLW9wYWNpdHk6MSIvPjwvbGluZWFyR3JhZGllbnQ+PGxp\n",
    "bmVhckdyYWRpZW50IHhsaW5rOmhyZWY9IiNhIiBpZD0iZSIgeDE9IjE1MC45NjEiIHgyPSIxMTIu\n",
    "MDMxIiB5MT0iMTkyLjM1MiIgeTI9IjEzNy4yNzMiIGdyYWRpZW50VHJhbnNmb3JtPSJtYXRyaXgo\n",
    "LjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRVbml0cz0idXNlclNw\n",
    "YWNlT25Vc2UiLz48bGluZWFyR3JhZGllbnQgeGxpbms6aHJlZj0iI2IiIGlkPSJkIiB4MT0iMjYu\n",
    "NjQ5IiB4Mj0iMTM1LjY2NSIgeTE9IjIwLjYwNCIgeTI9IjExNC4zOTgiIGdyYWRpZW50VHJhbnNm\n",
    "b3JtPSJtYXRyaXgoLjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRV\n",
    "bml0cz0idXNlclNwYWNlT25Vc2UiLz48cmFkaWFsR3JhZGllbnQgeGxpbms6aHJlZj0iI2MiIGlk\n",
    "PSJmIiBjeD0iNjEuNTE5IiBjeT0iMTMyLjI4NiIgcj0iMjkuMDM3IiBmeD0iNjEuNTE5IiBmeT0i\n",
    "MTMyLjI4NiIgZ3JhZGllbnRUcmFuc2Zvcm09Im1hdHJpeCgwIC0uMjM5OTUgMS4wNTQ2NyAwIC04\n",
    "My43IDE0Mi40NjIpIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIvPjwvZGVmcz48cGF0\n",
    "aCBkPSJNNTQuOTE5IDBjLTQuNTg0LjAyMi04Ljk2MS40MTMtMTIuODEzIDEuMDk1QzMwLjc2IDMu\n",
    "MDk5IDI4LjcgNy4yOTUgMjguNyAxNS4wMzJ2MTAuMjE5aDI2LjgxM3YzLjQwNkgxOC42MzhjLTcu\n",
    "NzkzIDAtMTQuNjE2IDQuNjg0LTE2Ljc1IDEzLjU5NC0yLjQ2MiAxMC4yMTMtMi41NzEgMTYuNTg2\n",
    "IDAgMjcuMjUgMS45MDUgNy45MzggNi40NTcgMTMuNTk0IDE0LjI1IDEzLjU5NGg5LjIxOHYtMTIu\n",
    "MjVjMC04Ljg1IDcuNjU3LTE2LjY1NyAxNi43NS0xNi42NTdoMjYuNzgyYzcuNDU0IDAgMTMuNDA2\n",
    "LTYuMTM4IDEzLjQwNi0xMy42MjV2LTI1LjUzYzAtNy4yNjctNi4xMy0xMi43MjYtMTMuNDA2LTEz\n",
    "LjkzOEM2NC4yODIuMzI4IDU5LjUwMi0uMDIgNTQuOTE4IDBtLTE0LjUgOC4yMmMyLjc3IDAgNS4w\n",
    "MzEgMi4yOTggNS4wMzEgNS4xMjUgMCAyLjgxNi0yLjI2MiA1LjA5My01LjAzMSA1LjA5My0yLjc4\n",
    "IDAtNS4wMzEtMi4yNzctNS4wMzEtNS4wOTMgMC0yLjgyNyAyLjI1MS01LjEyNSA1LjAzLTUuMTI1\n",
    "IiBzdHlsZT0iZmlsbDp1cmwoI2QpO2ZpbGwtb3BhY2l0eToxIi8+PHBhdGggZD0iTTg1LjYzOCAy\n",
    "OC42NTd2MTEuOTA2YzAgOS4yMzEtNy44MjYgMTctMTYuNzUgMTdINDIuMTA2Yy03LjMzNiAwLTEz\n",
    "LjQwNiA2LjI3OS0xMy40MDYgMTMuNjI1Vjk2LjcyYzAgNy4yNjYgNi4zMTkgMTEuNTQgMTMuNDA2\n",
    "IDEzLjYyNSA4LjQ4OCAyLjQ5NSAxNi42MjcgMi45NDYgMjYuNzgyIDAgNi43NS0xLjk1NSAxMy40\n",
    "MDYtNS44ODggMTMuNDA2LTEzLjYyNVY4Ni41SDU1LjUxM3YtMy40MDVIOTUuN2M3Ljc5MyAwIDEw\n",
    "LjY5Ni01LjQzNiAxMy40MDYtMTMuNTk0IDIuOC04LjM5OSAyLjY4LTE2LjQ3NiAwLTI3LjI1LTEu\n",
    "OTI1LTcuNzU4LTUuNjA0LTEzLjU5NC0xMy40MDYtMTMuNTk0ek03MC41NzUgOTMuMzEzYzIuNzgg\n",
    "MCA1LjAzMSAyLjI3OCA1LjAzMSA1LjA5NCAwIDIuODI3LTIuMjUxIDUuMTI1LTUuMDMxIDUuMTI1\n",
    "LTIuNzcgMC01LjAzMS0yLjI5OC01LjAzMS01LjEyNSAwLTIuODE2IDIuMjYxLTUuMDk0IDUuMDMx\n",
    "LTUuMDk0IiBzdHlsZT0iZmlsbDp1cmwoI2UpO2ZpbGwtb3BhY2l0eToxIi8+PGVsbGlwc2UgY3g9\n",
    "IjU1LjgxNyIgY3k9IjEyNy43MDEiIHJ4PSIzNS45MzEiIHJ5PSI2Ljk2NyIgc3R5bGU9Im9wYWNp\n",
    "dHk6LjQ0MzgyO2ZpbGw6dXJsKCNmKTtmaWxsLW9wYWNpdHk6MTtmaWxsLXJ1bGU6bm9uemVybztz\n",
    "dHJva2U6bm9uZTtzdHJva2Utd2lkdGg6MTUuNDE3NDtzdHJva2UtbWl0ZXJsaW1pdDo0O3N0cm9r\n",
    "ZS1kYXNoYXJyYXk6bm9uZTtzdHJva2Utb3BhY2l0eToxIi8+PC9zdmc+\n",
    "\"\n",
    "     style=\"display:block;margin:auto;width:10%\" alt=\"Python Logo\"/>\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align:center; font-size:200%;\">\n",
    " <b>LangChain: Framework für LLM-Anwendungen</b>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"text-align:center;\">Dr. Matthias Hölzl</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013590c99699344f",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Was wir bisher gemacht haben\n",
    "\n",
    "- LLM APIs direkt aufgerufen\n",
    "- Konversationsverlauf manuell verwaltet\n",
    "- Jede Funktion selbst geschrieben\n",
    "\n",
    "**Das funktioniert**, aber...\n",
    "- Viel Code für Standard-Aufgaben\n",
    "- Fehleranfällig\n",
    "- Schwer zu erweitern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7f223592e41ba0",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Die Lösung: LangChain\n",
    "\n",
    "- **Framework** für LLM-Anwendungen\n",
    "- **Vorgefertigte Komponenten** für häufige Aufgaben\n",
    "- **Weniger Code**, mehr Funktionalität\n",
    "- **Industrie-Standard** (in 60%+ der Job-Anzeigen!)\n",
    "\n",
    "**Installation**: `pip install langchain langchain-core langchain-openai langchain-anthropic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24930085a379a8a8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "keep",
     "subslide"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain-core langchain-openai langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246775ae2a597f0",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230acfe8e4018705",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feced98429e4578e",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369277b02914a6e9",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c340147f8ed995e",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff6e094859f63c",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## LangChain Komponenten\n",
    "\n",
    "1. **LLMs und Chat Models**: Wrapper für verschiedene Anbieter\n",
    "2. **Prompts**: Template-System für Prompts\n",
    "3. **Chains**: Kombination mehrerer Schritte\n",
    "4. **Memory**: Konversationsverlauf automatisch\n",
    "5. **Document Loaders**: Daten aus verschiedenen Quellen laden\n",
    "6. **Vector Stores**: Integration mit Vektor-Datenbanken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed118237a28ffae",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Einfacher LLM-Aufruf mit LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e58cc4541e164",
   "metadata": {
    "tags": [
     "start"
    ]
   },
   "outputs": [],
   "source": [
    "# Create LLM (using OpenRouter for access to many models)\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"mistralai/ministral-14b-2512\"\n",
    ")\n",
    "\n",
    "# Call it\n",
    "# TODO: Call llm.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a82c5240661262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c1d3d81cf5b7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "077106e40ebef90c",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Prompt Templates\n",
    "\n",
    "- **Problem**: Prompts mit Variablen sind umständlich mit String-Formatierung\n",
    "- **Lösung**: LangChain Prompt Templates\n",
    "- Wiederverwendbar, klar strukturiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02944b7d2755f779",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16152f0be7a308e8",
   "metadata": {
    "lang": "de"
   },
   "source": [
    "\n",
    "Erzeugen der Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498702f207243ab7",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful {subject} teacher.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb03561eb05683e",
   "metadata": {
    "lang": "de"
   },
   "source": [
    "\n",
    "Formatieren des Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b3b02bab14af28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "112c25141982fc43",
   "metadata": {
    "lang": "de"
   },
   "source": [
    "\n",
    "Aufrufen des LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37bb22afa2d2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87526139a547ee8b",
   "metadata": {
    "lang": "de"
   },
   "source": [
    "\n",
    "Anzeigen des Ergebnisses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3adff1be2429a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5fdbcc7e3d2dc40",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Chains: Schritte verketten\n",
    "\n",
    "- **Chain**: Verkettung mehrerer Komponenten\n",
    "- **Beispiel**: Prompt Template → LLM → Verarbeitung\n",
    "- Mit `|` Operator verknüpfen (LCEL - LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00434a8eda26922",
   "metadata": {
    "tags": [
     "start"
    ]
   },
   "outputs": [],
   "source": [
    "# Create chain\n",
    "chain = template | llm\n",
    "\n",
    "# Use chain\n",
    "# TODO: Invoke chain with inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4234f1e3a88a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09e6f5cc3eddeaa1",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Memory: Konversationsverlauf\n",
    "\n",
    "- LangChain kann Konversationsverlauf mit **RunnableWithMessageHistory** verwalten\n",
    "- Speichert Nachrichten in einer Session\n",
    "- Ermöglicht Zugriff auf Konversationskontext\n",
    "- Einfacher als manuelle Verwaltung!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c677c0f1fb651",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd780a103995ae",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6621e6b25579ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89af304d3844f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fca39245823fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83834a4743527c5a",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Document Loaders\n",
    "\n",
    "- Daten aus verschiedenen Quellen laden\n",
    "- **PDFs**, **Webseiten**, **Word-Dokumente**, etc.\n",
    "- Mit wenigen Zeilen Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7fa9772a4b8af",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Example: Load text file (if it exists)\n",
    "# loader = TextLoader(\"example.txt\")\n",
    "# documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a514e5ccce2f4f6f",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Vorher vs. Nachher: Chatbot-Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7398eeb3f7bd19ea",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Vorher (Ohne LangChain):\n",
    "- API-Client initialisieren\n",
    "- Nachrichtenverlauf manuell verwalten\n",
    "- Fehlerbehandlung selbst schreiben\n",
    "- ~50-80 Zeilen Code\n",
    "\n",
    "### Nachher (Mit LangChain):\n",
    "- LangChain Chat Model\n",
    "- RunnableWithMessageHistory für Memory\n",
    "- Automatische Fehlerbehandlung\n",
    "- ~15-20 Zeilen Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea380061e8c55eb",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Workshop: Professioneller Chatbot mit LangChain und Gradio\n",
    "\n",
    "**Ziel**: Einen vollständigen Chatbot mit professioneller Oberfläche bauen!\n",
    "\n",
    "Wir kombinieren:\n",
    "- LangChain für LLM-Integration\n",
    "- Gradio für die Benutzeroberfläche\n",
    "- Einstellbare Persönlichkeit\n",
    "- Temperatur-Kontrolle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5777c88c8865f5f3",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d1a7e7f79baa2a",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Teil 1: Basis-Chatbot mit LangChain\n",
    "\n",
    "Erstellen wir zunächst einen einfachen Chatbot mit LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11defa375859cf5",
   "metadata": {
    "tags": [
     "start"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Create LangChain chat model\n",
    "# workshop_llm = ChatOpenAI(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c74968c2384a6dd",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "start"
    ]
   },
   "outputs": [],
   "source": [
    "def simple_chatbot(message, history):\n",
    "    \"\"\"Simple chatbot function for Gradio\"\"\"\n",
    "    # TODO: Call LLM and return response\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90349dc2c7e94364",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Teil 2: Gradio Interface erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c59959456dc4b1d",
   "metadata": {
    "tags": [
     "start"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Create ChatInterface\n",
    "# demo = gr.ChatInterface(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9f2d664d01e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ee924dc6b2e2319",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "### Teil 3: Persönlichkeit hinzufügen\n",
    "\n",
    "- System-Prompt definiert die Persönlichkeit\n",
    "- Verschiedene Persönlichkeiten zur Auswahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d771bbfdbf420c",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "PERSONALITIES_DE = {\n",
    "    \"Freundlich\": \"Du bist ein freundlicher und hilfsbereiter Assistent.\",\n",
    "    \"Professionell\": \"Du bist ein professioneller und sachlicher Assistent.\",\n",
    "    \"Lustig\": \"Du bist ein humorvoller Assistent, der gerne Witze macht.\",\n",
    "}\n",
    "\n",
    "PERSONALITIES_EN = {\n",
    "    \"Friendly\": \"You are a friendly and helpful assistant.\",\n",
    "    \"Professional\": \"You are a professional and matter-of-fact assistant.\",\n",
    "    \"Funny\": \"You are a humorous assistant who likes to make jokes.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf2c88ee9e5bc39",
   "metadata": {
    "lang": "de",
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "PERSONALITIES = PERSONALITIES_DE\n",
    "DEFAULT_PERSONALITY = \"Freundlich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8bdedc4e4040a2",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "start"
    ]
   },
   "outputs": [],
   "source": [
    "def chatbot_with_personality(message, history, personality):\n",
    "    \"\"\"Chatbot with configurable personality\"\"\"\n",
    "    # TODO: Use personality in system prompt\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb63418469c45a",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "Chat Interface mit Persönlichkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaf0b5c330b0e7a",
   "metadata": {
    "tags": [
     "start"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Create ChatInterface with personality dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de0549fe9a60da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c321ea1464b7b553",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "### Teil 4: Temperatur-Kontrolle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b5ed179ad4467b",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "start"
    ]
   },
   "outputs": [],
   "source": [
    "def chatbot_full(message, history, personality, temperature):\n",
    "    \"\"\"Chatbot with all controls\"\"\"\n",
    "    # TODO: Implement with temperature control\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e065e39753074f6",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "### Teil 5: Vollständiges Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2aea15693c6261",
   "metadata": {
    "tags": [
     "start"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Create ChatInterface with all inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c51dde5db8206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ff269cabad8eef5",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "### Teil 6: Zusatzfunktionen (Optional)\n",
    "\n",
    "**Weitere Features, die Sie hinzufügen können**:\n",
    "- Export-Button für Konversation\n",
    "- Token-Zähler und Kosten-Tracker\n",
    "- Verschiedene Modelle zur Auswahl\n",
    "- Custom Styling/Theme\n",
    "- Beispiel-Prompts (Buttons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e2b712c9d88b8",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "### Beispiel-Anwendung: Kundenservice-Bot\n",
    "\n",
    "**Szenario**: Chatbot für einen Online-Shop\n",
    "- Beantwortet Fragen zu Produkten\n",
    "- Hilft bei Bestellungen\n",
    "- Professionelles Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663276be99e24fdb",
   "metadata": {
    "lang": "de",
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "CUSTOMER_SERVICE_PROMPT_DE = \"\"\"\\\n",
    "Du bist ein freundlicher Kundenservice-Mitarbeiter für einen Online-Shop.\n",
    "Du hilfst Kunden bei Fragen zu Produkten, Bestellungen und Versand.\n",
    "Sei höflich, hilfsbereit und professionell.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194d17180b32d52",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def customer_service_bot(message, history, temperature):\n",
    "    \"\"\"Customer service chatbot\"\"\"\n",
    "    try:\n",
    "        llm_cs = ChatOpenAI(\n",
    "            api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            model=\"mistralai/ministral-14b-2512\",\n",
    "            temperature=temperature\n",
    "        )\n",
    "\n",
    "        messages = [(\"system\", CUSTOMER_SERVICE_PROMPT_DE)]\n",
    "\n",
    "        # Convert history to LangChain format\n",
    "        for msg in history:\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                messages.append(HumanMessage(content=msg[\"content\"]))\n",
    "            elif msg[\"role\"] == \"assistant\":\n",
    "                messages.append(AIMessage(content=msg[\"content\"]))\n",
    "\n",
    "        # Add current message\n",
    "        messages.append(HumanMessage(content=message))\n",
    "\n",
    "        response = llm_cs.invoke(messages)\n",
    "        return response.content\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Entschuldigung, es gab einen Fehler: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7158741cf6c0c1",
   "metadata": {
    "lang": "de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254fac7457b87f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a3de017f02c532c",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Workshop-Aufgaben\n",
    "\n",
    "### Basis (Pflicht):\n",
    "1. Chatbot mit LangChain erstellen\n",
    "2. Gradio ChatInterface hinzufügen\n",
    "3. Persönlichkeits-Dropdown implementieren\n",
    "4. Temperatur-Slider implementieren\n",
    "5. Fehlerbehandlung testen\n",
    "\n",
    "### Erweitert (Optional):\n",
    "6. Export-Funktion hinzufügen\n",
    "7. Token-Counter einbauen\n",
    "8. Custom Theme gestalten\n",
    "9. Beispiel-Prompts als Buttons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39746dc5368071ae",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Zusammenfassung\n",
    "\n",
    "- **LangChain**: Framework für LLM-Anwendungen\n",
    "- **Komponenten**: LLMs, Prompts, Chains (LCEL), Memory, Loaders\n",
    "- **Vorteile**: Weniger Code, mehr Funktionalität\n",
    "- **Industrie-Standard**: Wichtig für Jobmarkt\n",
    "- **Workshop**: Vollständiger Chatbot mit Gradio\n",
    "\n",
    "**Nächster Schritt**: RAG-Systeme - Dokumente mit LLMs verbinden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e03423667dbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,lang,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
