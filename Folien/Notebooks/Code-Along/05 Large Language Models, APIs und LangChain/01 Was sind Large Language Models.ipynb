{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91fc2ed9cfe92ea",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "<img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRw\n",
    "Oi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMTExLjE2MSIgaGVpZ2h0PSIxMzQuNjY4\n",
    "IiB2ZXJzaW9uPSIxLjAiPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYyI+PHN0b3Agb2Zmc2V0\n",
    "PSIwIiBzdHlsZT0ic3RvcC1jb2xvcjojYjhiOGI4O3N0b3Atb3BhY2l0eTouNDk4MDM5MjIiLz48\n",
    "c3RvcCBvZmZzZXQ9IjEiIHN0eWxlPSJzdG9wLWNvbG9yOiM3ZjdmN2Y7c3RvcC1vcGFjaXR5OjAi\n",
    "Lz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYSI+PHN0b3Agb2Zmc2V0PSIw\n",
    "IiBzdHlsZT0ic3RvcC1jb2xvcjojZmZkNDNiO3N0b3Atb3BhY2l0eToxIi8+PHN0b3Agb2Zmc2V0\n",
    "PSIxIiBzdHlsZT0ic3RvcC1jb2xvcjojZmZlODczO3N0b3Atb3BhY2l0eToxIi8+PC9saW5lYXJH\n",
    "cmFkaWVudD48bGluZWFyR3JhZGllbnQgaWQ9ImIiPjxzdG9wIG9mZnNldD0iMCIgc3R5bGU9InN0\n",
    "b3AtY29sb3I6IzVhOWZkNDtzdG9wLW9wYWNpdHk6MSIvPjxzdG9wIG9mZnNldD0iMSIgc3R5bGU9\n",
    "InN0b3AtY29sb3I6IzMwNjk5ODtzdG9wLW9wYWNpdHk6MSIvPjwvbGluZWFyR3JhZGllbnQ+PGxp\n",
    "bmVhckdyYWRpZW50IHhsaW5rOmhyZWY9IiNhIiBpZD0iZSIgeDE9IjE1MC45NjEiIHgyPSIxMTIu\n",
    "MDMxIiB5MT0iMTkyLjM1MiIgeTI9IjEzNy4yNzMiIGdyYWRpZW50VHJhbnNmb3JtPSJtYXRyaXgo\n",
    "LjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRVbml0cz0idXNlclNw\n",
    "YWNlT25Vc2UiLz48bGluZWFyR3JhZGllbnQgeGxpbms6aHJlZj0iI2IiIGlkPSJkIiB4MT0iMjYu\n",
    "NjQ5IiB4Mj0iMTM1LjY2NSIgeTE9IjIwLjYwNCIgeTI9IjExNC4zOTgiIGdyYWRpZW50VHJhbnNm\n",
    "b3JtPSJtYXRyaXgoLjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRV\n",
    "bml0cz0idXNlclNwYWNlT25Vc2UiLz48cmFkaWFsR3JhZGllbnQgeGxpbms6aHJlZj0iI2MiIGlk\n",
    "PSJmIiBjeD0iNjEuNTE5IiBjeT0iMTMyLjI4NiIgcj0iMjkuMDM3IiBmeD0iNjEuNTE5IiBmeT0i\n",
    "MTMyLjI4NiIgZ3JhZGllbnRUcmFuc2Zvcm09Im1hdHJpeCgwIC0uMjM5OTUgMS4wNTQ2NyAwIC04\n",
    "My43IDE0Mi40NjIpIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIvPjwvZGVmcz48cGF0\n",
    "aCBkPSJNNTQuOTE5IDBjLTQuNTg0LjAyMi04Ljk2MS40MTMtMTIuODEzIDEuMDk1QzMwLjc2IDMu\n",
    "MDk5IDI4LjcgNy4yOTUgMjguNyAxNS4wMzJ2MTAuMjE5aDI2LjgxM3YzLjQwNkgxOC42MzhjLTcu\n",
    "NzkzIDAtMTQuNjE2IDQuNjg0LTE2Ljc1IDEzLjU5NC0yLjQ2MiAxMC4yMTMtMi41NzEgMTYuNTg2\n",
    "IDAgMjcuMjUgMS45MDUgNy45MzggNi40NTcgMTMuNTk0IDE0LjI1IDEzLjU5NGg5LjIxOHYtMTIu\n",
    "MjVjMC04Ljg1IDcuNjU3LTE2LjY1NyAxNi43NS0xNi42NTdoMjYuNzgyYzcuNDU0IDAgMTMuNDA2\n",
    "LTYuMTM4IDEzLjQwNi0xMy42MjV2LTI1LjUzYzAtNy4yNjctNi4xMy0xMi43MjYtMTMuNDA2LTEz\n",
    "LjkzOEM2NC4yODIuMzI4IDU5LjUwMi0uMDIgNTQuOTE4IDBtLTE0LjUgOC4yMmMyLjc3IDAgNS4w\n",
    "MzEgMi4yOTggNS4wMzEgNS4xMjUgMCAyLjgxNi0yLjI2MiA1LjA5My01LjAzMSA1LjA5My0yLjc4\n",
    "IDAtNS4wMzEtMi4yNzctNS4wMzEtNS4wOTMgMC0yLjgyNyAyLjI1MS01LjEyNSA1LjAzLTUuMTI1\n",
    "IiBzdHlsZT0iZmlsbDp1cmwoI2QpO2ZpbGwtb3BhY2l0eToxIi8+PHBhdGggZD0iTTg1LjYzOCAy\n",
    "OC42NTd2MTEuOTA2YzAgOS4yMzEtNy44MjYgMTctMTYuNzUgMTdINDIuMTA2Yy03LjMzNiAwLTEz\n",
    "LjQwNiA2LjI3OS0xMy40MDYgMTMuNjI1Vjk2LjcyYzAgNy4yNjYgNi4zMTkgMTEuNTQgMTMuNDA2\n",
    "IDEzLjYyNSA4LjQ4OCAyLjQ5NSAxNi42MjcgMi45NDYgMjYuNzgyIDAgNi43NS0xLjk1NSAxMy40\n",
    "MDYtNS44ODggMTMuNDA2LTEzLjYyNVY4Ni41SDU1LjUxM3YtMy40MDVIOTUuN2M3Ljc5MyAwIDEw\n",
    "LjY5Ni01LjQzNiAxMy40MDYtMTMuNTk0IDIuOC04LjM5OSAyLjY4LTE2LjQ3NiAwLTI3LjI1LTEu\n",
    "OTI1LTcuNzU4LTUuNjA0LTEzLjU5NC0xMy40MDYtMTMuNTk0ek03MC41NzUgOTMuMzEzYzIuNzgg\n",
    "MCA1LjAzMSAyLjI3OCA1LjAzMSA1LjA5NCAwIDIuODI3LTIuMjUxIDUuMTI1LTUuMDMxIDUuMTI1\n",
    "LTIuNzcgMC01LjAzMS0yLjI5OC01LjAzMS01LjEyNSAwLTIuODE2IDIuMjYxLTUuMDk0IDUuMDMx\n",
    "LTUuMDk0IiBzdHlsZT0iZmlsbDp1cmwoI2UpO2ZpbGwtb3BhY2l0eToxIi8+PGVsbGlwc2UgY3g9\n",
    "IjU1LjgxNyIgY3k9IjEyNy43MDEiIHJ4PSIzNS45MzEiIHJ5PSI2Ljk2NyIgc3R5bGU9Im9wYWNp\n",
    "dHk6LjQ0MzgyO2ZpbGw6dXJsKCNmKTtmaWxsLW9wYWNpdHk6MTtmaWxsLXJ1bGU6bm9uemVybztz\n",
    "dHJva2U6bm9uZTtzdHJva2Utd2lkdGg6MTUuNDE3NDtzdHJva2UtbWl0ZXJsaW1pdDo0O3N0cm9r\n",
    "ZS1kYXNoYXJyYXk6bm9uZTtzdHJva2Utb3BhY2l0eToxIi8+PC9zdmc+\n",
    "\"\n",
    "     style=\"display:block;margin:auto;width:10%\" alt=\"Python Logo\"/>\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align:center; font-size:200%;\">\n",
    " <b>Was sind Large Language Models?</b>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"text-align:center;\">Dr. Matthias Hölzl</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4edd147e9386a6",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Die Revolution der letzten Jahre\n",
    "\n",
    "- **ChatGPT** (Ende 2022): Über 100 Millionen Nutzer in 2 Monaten\n",
    "- **Large Language Models (LLMs)** überall\n",
    "- Können Texte verstehen, generieren, übersetzen, zusammenfassen\n",
    "- Aber was genau sind sie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd25a46c2b30e72",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from what_are_llms_azav_plots import (plot_llm_timeline, plot_llm_capabilities,\n",
    "                        plot_training_data_sources, plot_training_stages,\n",
    "                        plot_emergent_abilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd3d6249a7a8c3",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe0d303768d223d",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Definition: Large Language Model\n",
    "\n",
    "- **Large**: Milliarden von Parametern\n",
    "- **Language**: Auf Text trainiert\n",
    "- **Model**: Neuronales Netz (Transformer)\n",
    "- Trainiert auf riesigen Textmengen (Bücher, Websites, etc.)\n",
    "- Lernt Muster, Grammatik, Fakten, Logik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722771e002562cb2",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Wie funktionieren LLMs?\n",
    "\n",
    "**Kernprinzip: Nächstes Token vorhersagen**\n",
    "\n",
    "- LLM sieht: \"Der Hund jagt die ___\"\n",
    "- LLM berechnet Wahrscheinlichkeiten für das nächste Wort\n",
    "- \"Katze\" (30%), \"Maus\" (25%), \"Ball\" (15%), ...\n",
    "- LLM wählt (meistens) das wahrscheinlichste Wort\n",
    "\n",
    "**Wichtig**: LLMs \"denken\" nicht - sie sagen Muster vorher!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da756bc94101792",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Token für Token\n",
    "\n",
    "So entsteht Text:\n",
    "\n",
    "1. \"Der\" → \"Der Hund\" (wahrscheinlichstes nächstes Wort)\n",
    "2. \"Der Hund\" → \"Der Hund jagt\" (wahrscheinlichstes nächstes Wort)\n",
    "3. \"Der Hund jagt\" → \"Der Hund jagt die\" → ...\n",
    "\n",
    "Das LLM generiert **ein Wort nach dem anderen**, basierend auf allem,\n",
    "was vorher kam.\n",
    "\n",
    "Das erklärt auch, warum LLMs manchmal \"Unsinn\" erzählen: Sie folgen\n",
    "statistisch wahrscheinlichen Mustern, nicht Fakten!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540ca8a9089654ac",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Bekannte LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37586f6a3d3b62a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd7625794534e400",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Was können LLMs?\n",
    "\n",
    "- **Text-Generierung**: Artikel, Geschichten, Code schreiben\n",
    "- **Übersetzung**: Zwischen Sprachen übersetzen\n",
    "- **Zusammenfassung**: Lange Texte zusammenfassen\n",
    "- **Fragen beantworten**: Auf Wissensfragen antworten\n",
    "- **Code schreiben**: Programmier-Aufgaben lösen\n",
    "- **Konversation**: Natürliche Gespräche führen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc59d8f26a1d2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fce8ef8d91dfd49",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Kontext-Fenster (Context Window)\n",
    "\n",
    "**Wie viel Text kann ein LLM auf einmal \"sehen\"?**\n",
    "\n",
    "- **Kontext-Fenster**: Maximale Textmenge für eine Anfrage\n",
    "- Gemessen in **Tokens** (~ Wortteile)\n",
    "- Faustregel: **1 Token ≈ 0,75 Wörter** (oder 3-4 Zeichen)\n",
    "\n",
    "| Jahr | Typisches Kontext-Fenster |\n",
    "|------|---------------------------|\n",
    "| 2023 | 4.000 - 8.000 Tokens |\n",
    "| 2024 | 128.000 - 200.000 Tokens |\n",
    "| 2025 | Bis zu 1.000.000 Tokens |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3430aa559db14aa7",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Was bedeutet das praktisch?\n",
    "\n",
    "- **4.000 Tokens** ≈ 3.000 Wörter ≈ 6 Seiten Text\n",
    "- **128.000 Tokens** ≈ 96.000 Wörter ≈ Ein kurzes Buch!\n",
    "- **1.000.000 Tokens** ≈ 750.000 Wörter ≈ Mehrere Bücher\n",
    "\n",
    "**Praktische Bedeutung:**\n",
    "- Längere Gespräche möglich\n",
    "- Ganze Dokumente analysieren\n",
    "- Mehr Kontext = bessere Antworten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30493fec636d185c",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Wie groß ist \"Large\"?\n",
    "\n",
    "- **GPT-2** (2019): 1.5 Milliarden Parameter\n",
    "- **GPT-3** (2020): 175 Milliarden Parameter\n",
    "- **GPT-4** (2023): ~1 Billion Parameter (geschätzt)\n",
    "- Zum Vergleich:\n",
    "  - Menschliches Gehirn: ~86 Milliarden Neuronen\n",
    "  - Aber: Parameter ≠ Neuronen!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f5894273d87304",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Training eines LLM\n",
    "\n",
    "- **Riesige Datenmengen**: Terabytes von Text\n",
    "- **Rechenleistung**: Tausende GPUs über Monate\n",
    "- **Kosten**: Millionen von Dollar\n",
    "- **Ziel**: Nächstes Wort vorhersagen\n",
    "- \"The cat sat on the ___\" → \"mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb52108e8f03cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dc495ea60090c7a",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Pre-Training vs. Fine-Tuning\n",
    "\n",
    "- **Pre-Training**: Auf allgemeinen Daten trainieren\n",
    "  - Lernt Sprache, Fakten, Logik\n",
    "  - Sehr teuer\n",
    "- **Fine-Tuning**: Auf spezielle Aufgaben anpassen\n",
    "  - Konversation, Instruktionen befolgen\n",
    "  - Viel günstiger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3295adadaa83ab2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b4fe8d206856301",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Emergent Abilities (?)\n",
    "\n",
    "Angeblich:\n",
    "\n",
    "- Bei einer gewissen Größe: **Neue Fähigkeiten tauchen auf**\n",
    "- Kleinere Modelle können es nicht\n",
    "- Größere Modelle plötzlich schon!\n",
    "- Beispiele:\n",
    "  - Mathematik\n",
    "  - Logisches Schließen\n",
    "  - Multi-Step-Reasoning\n",
    "\n",
    "Allerdings umstritten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88304ca6cd610c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f19c85f5681f416e",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Limitierungen von LLMs\n",
    "\n",
    "- **Halluzinationen**: Erfinden manchmal Fakten\n",
    "- **Wissens-Cutoff**: Wissen nur bis zu einem bestimmten Datum\n",
    "- **Kein echtes Verständnis**: Muster-Matching, nicht \"Denken\"\n",
    "- **Bias**: Vorurteile aus Trainingsdaten\n",
    "- **Rechenintensiv**: Brauchen viel Energie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0627007a18286058",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Halluzinationen: Die Zahlen\n",
    "\n",
    "**Studien zeigen:**\n",
    "\n",
    "- **~20%** der von LLMs vorgeschlagenen Software-Pakete existieren nicht!\n",
    "- **~48%** des von LLMs generierten Codes enthält Sicherheitslücken\n",
    "- LLMs klingen **sehr überzeugend**, auch wenn sie falsch liegen\n",
    "\n",
    "**Warum?** LLMs sagen wahrscheinliche Muster vorher, nicht Fakten.\n",
    "\"requests-auth-helper\" klingt wie ein echtes Paket - ist es aber nicht!\n",
    "\n",
    "**Regel**: Immer verifizieren, nie blind vertrauen!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acec3d0b0c4b9004",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Zusammenfassung\n",
    "\n",
    "- **LLMs**: Riesige neuronale Netze für Text\n",
    "- **Basierend auf Transformers** (Attention-Mechanismus)\n",
    "- **Trainiert auf Milliarden von Wörtern**\n",
    "- **Können viele Aufgaben**: Schreiben, Übersetzen, Fragen beantworten\n",
    "- **Emergent Abilities**: Neue Fähigkeiten bei größeren Modellen\n",
    "- **Limitierungen**: Halluzinationen, Bias, kein echtes Verständnis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b595b82bbb6d0",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Workshop: LLMs erkunden\n",
    "\n",
    "**Aufgaben** (nutzen Sie ChatGPT, Claude oder ein anderes LLM):\n",
    "\n",
    "1. **Verschiedene Prompts testen**: Stellen Sie die gleiche Frage\n",
    "   auf 3 verschiedene Arten - beobachten Sie die Unterschiede\n",
    "\n",
    "2. **Token-Generierung beobachten**: Aktivieren Sie \"Streaming\" und\n",
    "   beobachten Sie, wie der Text Wort für Wort erscheint\n",
    "\n",
    "3. **Wissens-Cutoff testen**: Fragen Sie nach aktuellen Ereignissen\n",
    "   (z.B. \"Wer hat die Bundestagswahl 2025 gewonnen?\")\n",
    "\n",
    "4. **Halluzination provozieren**: Fragen Sie nach einem erfundenen\n",
    "   Buch oder Paket (z.B. \"Erklären Sie das Python-Paket 'super-data-magic'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148286955e2aa612",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Workshop: Tipps\n",
    "\n",
    "**Für Aufgabe 1 (Verschiedene Prompts):**\n",
    "- Kurz: \"Was ist Python?\"\n",
    "- Mittel: \"Erklären Sie Python für Anfänger\"\n",
    "- Lang: \"Sie sind ein erfahrener Lehrer. Erklären Sie einem Anfänger,\n",
    "  was Python ist und warum es beliebt ist. Maximal 3 Sätze.\"\n",
    "\n",
    "**Für Aufgabe 4 (Halluzination):**\n",
    "- Beobachten Sie, wie überzeugend die Antwort klingt\n",
    "- Überprüfen Sie: Existiert das Paket wirklich? (`pip search` oder Google)\n",
    "- Das ist ein wichtiger Grund, warum wir LLM-Output immer prüfen!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe514b1757904617",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## In der nächsten Lektion\n",
    "\n",
    "- **Prompt Engineering**: Die Kunst, gute Prompts zu schreiben\n",
    "- Techniken für bessere LLM-Antworten\n",
    "- Praktische Tipps und Muster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e03423667dbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,lang,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
