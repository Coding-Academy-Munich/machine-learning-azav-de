{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ecf2c6ad89b7f3",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "<img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRw\n",
    "Oi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMTExLjE2MSIgaGVpZ2h0PSIxMzQuNjY4\n",
    "IiB2ZXJzaW9uPSIxLjAiPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYyI+PHN0b3Agb2Zmc2V0\n",
    "PSIwIiBzdHlsZT0ic3RvcC1jb2xvcjojYjhiOGI4O3N0b3Atb3BhY2l0eTouNDk4MDM5MjIiLz48\n",
    "c3RvcCBvZmZzZXQ9IjEiIHN0eWxlPSJzdG9wLWNvbG9yOiM3ZjdmN2Y7c3RvcC1vcGFjaXR5OjAi\n",
    "Lz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYSI+PHN0b3Agb2Zmc2V0PSIw\n",
    "IiBzdHlsZT0ic3RvcC1jb2xvcjojZmZkNDNiO3N0b3Atb3BhY2l0eToxIi8+PHN0b3Agb2Zmc2V0\n",
    "PSIxIiBzdHlsZT0ic3RvcC1jb2xvcjojZmZlODczO3N0b3Atb3BhY2l0eToxIi8+PC9saW5lYXJH\n",
    "cmFkaWVudD48bGluZWFyR3JhZGllbnQgaWQ9ImIiPjxzdG9wIG9mZnNldD0iMCIgc3R5bGU9InN0\n",
    "b3AtY29sb3I6IzVhOWZkNDtzdG9wLW9wYWNpdHk6MSIvPjxzdG9wIG9mZnNldD0iMSIgc3R5bGU9\n",
    "InN0b3AtY29sb3I6IzMwNjk5ODtzdG9wLW9wYWNpdHk6MSIvPjwvbGluZWFyR3JhZGllbnQ+PGxp\n",
    "bmVhckdyYWRpZW50IHhsaW5rOmhyZWY9IiNhIiBpZD0iZSIgeDE9IjE1MC45NjEiIHgyPSIxMTIu\n",
    "MDMxIiB5MT0iMTkyLjM1MiIgeTI9IjEzNy4yNzMiIGdyYWRpZW50VHJhbnNmb3JtPSJtYXRyaXgo\n",
    "LjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRVbml0cz0idXNlclNw\n",
    "YWNlT25Vc2UiLz48bGluZWFyR3JhZGllbnQgeGxpbms6aHJlZj0iI2IiIGlkPSJkIiB4MT0iMjYu\n",
    "NjQ5IiB4Mj0iMTM1LjY2NSIgeTE9IjIwLjYwNCIgeTI9IjExNC4zOTgiIGdyYWRpZW50VHJhbnNm\n",
    "b3JtPSJtYXRyaXgoLjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRV\n",
    "bml0cz0idXNlclNwYWNlT25Vc2UiLz48cmFkaWFsR3JhZGllbnQgeGxpbms6aHJlZj0iI2MiIGlk\n",
    "PSJmIiBjeD0iNjEuNTE5IiBjeT0iMTMyLjI4NiIgcj0iMjkuMDM3IiBmeD0iNjEuNTE5IiBmeT0i\n",
    "MTMyLjI4NiIgZ3JhZGllbnRUcmFuc2Zvcm09Im1hdHJpeCgwIC0uMjM5OTUgMS4wNTQ2NyAwIC04\n",
    "My43IDE0Mi40NjIpIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIvPjwvZGVmcz48cGF0\n",
    "aCBkPSJNNTQuOTE5IDBjLTQuNTg0LjAyMi04Ljk2MS40MTMtMTIuODEzIDEuMDk1QzMwLjc2IDMu\n",
    "MDk5IDI4LjcgNy4yOTUgMjguNyAxNS4wMzJ2MTAuMjE5aDI2LjgxM3YzLjQwNkgxOC42MzhjLTcu\n",
    "NzkzIDAtMTQuNjE2IDQuNjg0LTE2Ljc1IDEzLjU5NC0yLjQ2MiAxMC4yMTMtMi41NzEgMTYuNTg2\n",
    "IDAgMjcuMjUgMS45MDUgNy45MzggNi40NTcgMTMuNTk0IDE0LjI1IDEzLjU5NGg5LjIxOHYtMTIu\n",
    "MjVjMC04Ljg1IDcuNjU3LTE2LjY1NyAxNi43NS0xNi42NTdoMjYuNzgyYzcuNDU0IDAgMTMuNDA2\n",
    "LTYuMTM4IDEzLjQwNi0xMy42MjV2LTI1LjUzYzAtNy4yNjctNi4xMy0xMi43MjYtMTMuNDA2LTEz\n",
    "LjkzOEM2NC4yODIuMzI4IDU5LjUwMi0uMDIgNTQuOTE4IDBtLTE0LjUgOC4yMmMyLjc3IDAgNS4w\n",
    "MzEgMi4yOTggNS4wMzEgNS4xMjUgMCAyLjgxNi0yLjI2MiA1LjA5My01LjAzMSA1LjA5My0yLjc4\n",
    "IDAtNS4wMzEtMi4yNzctNS4wMzEtNS4wOTMgMC0yLjgyNyAyLjI1MS01LjEyNSA1LjAzLTUuMTI1\n",
    "IiBzdHlsZT0iZmlsbDp1cmwoI2QpO2ZpbGwtb3BhY2l0eToxIi8+PHBhdGggZD0iTTg1LjYzOCAy\n",
    "OC42NTd2MTEuOTA2YzAgOS4yMzEtNy44MjYgMTctMTYuNzUgMTdINDIuMTA2Yy03LjMzNiAwLTEz\n",
    "LjQwNiA2LjI3OS0xMy40MDYgMTMuNjI1Vjk2LjcyYzAgNy4yNjYgNi4zMTkgMTEuNTQgMTMuNDA2\n",
    "IDEzLjYyNSA4LjQ4OCAyLjQ5NSAxNi42MjcgMi45NDYgMjYuNzgyIDAgNi43NS0xLjk1NSAxMy40\n",
    "MDYtNS44ODggMTMuNDA2LTEzLjYyNVY4Ni41SDU1LjUxM3YtMy40MDVIOTUuN2M3Ljc5MyAwIDEw\n",
    "LjY5Ni01LjQzNiAxMy40MDYtMTMuNTk0IDIuOC04LjM5OSAyLjY4LTE2LjQ3NiAwLTI3LjI1LTEu\n",
    "OTI1LTcuNzU4LTUuNjA0LTEzLjU5NC0xMy40MDYtMTMuNTk0ek03MC41NzUgOTMuMzEzYzIuNzgg\n",
    "MCA1LjAzMSAyLjI3OCA1LjAzMSA1LjA5NCAwIDIuODI3LTIuMjUxIDUuMTI1LTUuMDMxIDUuMTI1\n",
    "LTIuNzcgMC01LjAzMS0yLjI5OC01LjAzMS01LjEyNSAwLTIuODE2IDIuMjYxLTUuMDk0IDUuMDMx\n",
    "LTUuMDk0IiBzdHlsZT0iZmlsbDp1cmwoI2UpO2ZpbGwtb3BhY2l0eToxIi8+PGVsbGlwc2UgY3g9\n",
    "IjU1LjgxNyIgY3k9IjEyNy43MDEiIHJ4PSIzNS45MzEiIHJ5PSI2Ljk2NyIgc3R5bGU9Im9wYWNp\n",
    "dHk6LjQ0MzgyO2ZpbGw6dXJsKCNmKTtmaWxsLW9wYWNpdHk6MTtmaWxsLXJ1bGU6bm9uemVybztz\n",
    "dHJva2U6bm9uZTtzdHJva2Utd2lkdGg6MTUuNDE3NDtzdHJva2UtbWl0ZXJsaW1pdDo0O3N0cm9r\n",
    "ZS1kYXNoYXJyYXk6bm9uZTtzdHJva2Utb3BhY2l0eToxIi8+PC9zdmc+\n",
    "\"\n",
    "     style=\"display:block;margin:auto;width:10%\" alt=\"Python Logo\"/>\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align:center; font-size:200%;\">\n",
    " <b>Gradientenabstieg</b>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"text-align:center;\">Dr. Matthias Hölzl</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a8a5a980e3b44e",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Die große Frage\n",
    "\n",
    "- Wir wissen: Das Netz minimiert den Fehler\n",
    "- Aber **wie genau** findet es die besten Parameter?\n",
    "- Die Antwort: **Gradientenabstieg** (Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a97332ae3ce9f9",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Eine Analogie: Abstieg vom Berg\n",
    "\n",
    "- Stellen Sie sich vor, Sie stehen auf einem Berg\n",
    "- Es ist neblig, Sie können nur wenige Meter weit sehen\n",
    "- Ihr Ziel: Ins Tal hinabsteigen\n",
    "- Wie finden Sie den Weg?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e5513c4b6686eb",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Die Strategie\n",
    "\n",
    "1. Schauen Sie sich um (im Nebel)\n",
    "2. Finden Sie die steilste Stelle nach unten\n",
    "3. Machen Sie einen Schritt in diese Richtung\n",
    "4. Wiederholen Sie, bis Sie im Tal sind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5b46d32dd09680",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Gradientenabstieg funktioniert genauso!\n",
    "\n",
    "- **Berg** = Loss-Funktion (Fehler)\n",
    "- **Tal** = Minimaler Fehler (bestes Modell)\n",
    "- **Steilste Stelle** = Gradient\n",
    "- **Schritt** = Parameter-Update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ad305fa0cc280",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Visualisierung: Einfache Fehler-Landschaft\n",
    "\n",
    "- Stellen wir uns vor, wir haben nur einen Parameter\n",
    "- Die x-Achse zeigt den Parameterwert\n",
    "- Die y-Achse zeigt den Fehler (Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a7cb19d6c5df6",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from nn_training_essentials_plots import plot_simple_loss_landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb566419b0fc195c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef77af8b535bba24",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Schrittweiser Abstieg\n",
    "\n",
    "- Wir starten irgendwo auf dem \"Berg\"\n",
    "- Bei jedem Schritt gehen wir bergab\n",
    "- Der Gradient zeigt uns die Richtung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08927ffbde9fd3ef",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from nn_training_essentials_plots import plot_gradient_descent_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457de12cffbaa29",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48fb4caedf4d2dbc",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Was ist der Gradient?\n",
    "\n",
    "- Der **Gradient** ist die Steigung der Fehler-Funktion\n",
    "- Er zeigt in die Richtung des steilsten **Anstiegs**\n",
    "- Wir gehen in die **entgegengesetzte** Richtung (bergab)\n",
    "- Mathematisch: Eine Ableitung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169e9e5512663d5",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## 2D-Beispiel: Zwei Parameter\n",
    "\n",
    "- Neuronale Netze haben viele Parameter\n",
    "- Schauen wir uns zwei Parameter an\n",
    "- Die Fehler-Landschaft wird zu einem Gebirge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8581bd1893dda15b",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from nn_training_essentials_plots import plot_2d_loss_landscape, plot_2d_loss_landscape_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795186652a5c580c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d48e6eacf41a0d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f8b37c2d9276fd6",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Das Problem: Lokale Minima\n",
    "\n",
    "- Unsere Analogie hat einen Haken!\n",
    "- Was passiert, wenn es mehrere Täler gibt?\n",
    "- Sie könnten in einem kleinen Tal landen, nicht im tiefsten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b80295cb4db1b",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "<img src=\"../../../../img/Funtensee-1.jpg\" style=\"width:40%;float:right;margin-left:10px;\"/>\n",
    "\n",
    "## Beispiel: Der Funtensee\n",
    "\n",
    "<ul>\n",
    "  <li>See in den Berchtesgadener Alpen</li>\n",
    "  <li>In einem Tal, das von höheren Bergen<br>umgeben ist</li>\n",
    "  <li>Kältester Ort Deutschlands</li>\n",
    "  <li>Wenn Sie dort landen, denken Sie vielleicht,<br>Sie sind am tiefsten Punkt</li>\n",
    "  <li>Aber Sie sind immer noch 1601 Meter hoch!</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb397d81a03d2ff",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "<img src=\"../../../../img/Funtensee-2.jpg\" style=\"width:80%;margin-left:10px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef285b7540c4418a",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from nn_training_essentials_plots import plot_funtensee_local_minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799ece40f415f5f8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b3c3cafe9ac2c56",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Lokales vs. Globales Minimum\n",
    "\n",
    "- **Lokales Minimum**: Ein Tal, aber nicht das tiefste\n",
    "- **Globales Minimum**: Das tiefste Tal überhaupt\n",
    "- Problem: Gradient Descent kann in lokalem Minimum stecken bleiben\n",
    "- Wie der Funtensee: Ein Tal, aber nicht das tiefste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6956caad5e3acdc2",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Demonstration: Wo man startet, ist wichtig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a5bf021616502",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from nn_training_essentials_plots import plot_starting_point_matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22912afe337f6189",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0fb47c6269b98fc",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Die Lernrate\n",
    "\n",
    "- Wie groß soll der Schritt sein?\n",
    "- Die **Lernrate** (Learning Rate) steuert die Schrittgröße\n",
    "- **Zu groß**: Man springt über das Minimum hinweg\n",
    "- **Zu klein**: Man braucht sehr lange\n",
    "- **Genau richtig**: Effizientes Lernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ac395818cb88a",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from nn_training_essentials_plots import plot_learning_rate_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57962d0c9f299119",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "598eef3ac4f3fc4b",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## In der Praxis\n",
    "\n",
    "- Neuronale Netze haben Hunderte oder Tausende von Parametern\n",
    "- Der Gradient zeigt für jeden Parameter die Richtung\n",
    "- Moderne Optimierer (wie Adam) passen die Lernrate automatisch an\n",
    "- Sie helfen, lokale Minima zu vermeiden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50dadb9d6e4a9d9",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Zusammenfassung\n",
    "\n",
    "- **Gradientenabstieg** = Methode zum Finden des Minimums\n",
    "- **Gradient** = Richtung des steilsten Anstiegs\n",
    "- Wir gehen in die entgegengesetzte Richtung (bergab)\n",
    "- **Lernrate** steuert die Schrittgröße\n",
    "- **Lokale Minima** wie der Funtensee sind ein Problem\n",
    "- Moderne Optimierer helfen, gute Lösungen zu finden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e03423667dbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "lang,tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
