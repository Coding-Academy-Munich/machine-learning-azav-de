{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70aef80ed820a0d2",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "<img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRw\n",
    "Oi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMTExLjE2MSIgaGVpZ2h0PSIxMzQuNjY4\n",
    "IiB2ZXJzaW9uPSIxLjAiPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYyI+PHN0b3Agb2Zmc2V0\n",
    "PSIwIiBzdHlsZT0ic3RvcC1jb2xvcjojYjhiOGI4O3N0b3Atb3BhY2l0eTouNDk4MDM5MjIiLz48\n",
    "c3RvcCBvZmZzZXQ9IjEiIHN0eWxlPSJzdG9wLWNvbG9yOiM3ZjdmN2Y7c3RvcC1vcGFjaXR5OjAi\n",
    "Lz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYSI+PHN0b3Agb2Zmc2V0PSIw\n",
    "IiBzdHlsZT0ic3RvcC1jb2xvcjojZmZkNDNiO3N0b3Atb3BhY2l0eToxIi8+PHN0b3Agb2Zmc2V0\n",
    "PSIxIiBzdHlsZT0ic3RvcC1jb2xvcjojZmZlODczO3N0b3Atb3BhY2l0eToxIi8+PC9saW5lYXJH\n",
    "cmFkaWVudD48bGluZWFyR3JhZGllbnQgaWQ9ImIiPjxzdG9wIG9mZnNldD0iMCIgc3R5bGU9InN0\n",
    "b3AtY29sb3I6IzVhOWZkNDtzdG9wLW9wYWNpdHk6MSIvPjxzdG9wIG9mZnNldD0iMSIgc3R5bGU9\n",
    "InN0b3AtY29sb3I6IzMwNjk5ODtzdG9wLW9wYWNpdHk6MSIvPjwvbGluZWFyR3JhZGllbnQ+PGxp\n",
    "bmVhckdyYWRpZW50IHhsaW5rOmhyZWY9IiNhIiBpZD0iZSIgeDE9IjE1MC45NjEiIHgyPSIxMTIu\n",
    "MDMxIiB5MT0iMTkyLjM1MiIgeTI9IjEzNy4yNzMiIGdyYWRpZW50VHJhbnNmb3JtPSJtYXRyaXgo\n",
    "LjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRVbml0cz0idXNlclNw\n",
    "YWNlT25Vc2UiLz48bGluZWFyR3JhZGllbnQgeGxpbms6aHJlZj0iI2IiIGlkPSJkIiB4MT0iMjYu\n",
    "NjQ5IiB4Mj0iMTM1LjY2NSIgeTE9IjIwLjYwNCIgeTI9IjExNC4zOTgiIGdyYWRpZW50VHJhbnNm\n",
    "b3JtPSJtYXRyaXgoLjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRV\n",
    "bml0cz0idXNlclNwYWNlT25Vc2UiLz48cmFkaWFsR3JhZGllbnQgeGxpbms6aHJlZj0iI2MiIGlk\n",
    "PSJmIiBjeD0iNjEuNTE5IiBjeT0iMTMyLjI4NiIgcj0iMjkuMDM3IiBmeD0iNjEuNTE5IiBmeT0i\n",
    "MTMyLjI4NiIgZ3JhZGllbnRUcmFuc2Zvcm09Im1hdHJpeCgwIC0uMjM5OTUgMS4wNTQ2NyAwIC04\n",
    "My43IDE0Mi40NjIpIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIvPjwvZGVmcz48cGF0\n",
    "aCBkPSJNNTQuOTE5IDBjLTQuNTg0LjAyMi04Ljk2MS40MTMtMTIuODEzIDEuMDk1QzMwLjc2IDMu\n",
    "MDk5IDI4LjcgNy4yOTUgMjguNyAxNS4wMzJ2MTAuMjE5aDI2LjgxM3YzLjQwNkgxOC42MzhjLTcu\n",
    "NzkzIDAtMTQuNjE2IDQuNjg0LTE2Ljc1IDEzLjU5NC0yLjQ2MiAxMC4yMTMtMi41NzEgMTYuNTg2\n",
    "IDAgMjcuMjUgMS45MDUgNy45MzggNi40NTcgMTMuNTk0IDE0LjI1IDEzLjU5NGg5LjIxOHYtMTIu\n",
    "MjVjMC04Ljg1IDcuNjU3LTE2LjY1NyAxNi43NS0xNi42NTdoMjYuNzgyYzcuNDU0IDAgMTMuNDA2\n",
    "LTYuMTM4IDEzLjQwNi0xMy42MjV2LTI1LjUzYzAtNy4yNjctNi4xMy0xMi43MjYtMTMuNDA2LTEz\n",
    "LjkzOEM2NC4yODIuMzI4IDU5LjUwMi0uMDIgNTQuOTE4IDBtLTE0LjUgOC4yMmMyLjc3IDAgNS4w\n",
    "MzEgMi4yOTggNS4wMzEgNS4xMjUgMCAyLjgxNi0yLjI2MiA1LjA5My01LjAzMSA1LjA5My0yLjc4\n",
    "IDAtNS4wMzEtMi4yNzctNS4wMzEtNS4wOTMgMC0yLjgyNyAyLjI1MS01LjEyNSA1LjAzLTUuMTI1\n",
    "IiBzdHlsZT0iZmlsbDp1cmwoI2QpO2ZpbGwtb3BhY2l0eToxIi8+PHBhdGggZD0iTTg1LjYzOCAy\n",
    "OC42NTd2MTEuOTA2YzAgOS4yMzEtNy44MjYgMTctMTYuNzUgMTdINDIuMTA2Yy03LjMzNiAwLTEz\n",
    "LjQwNiA2LjI3OS0xMy40MDYgMTMuNjI1Vjk2LjcyYzAgNy4yNjYgNi4zMTkgMTEuNTQgMTMuNDA2\n",
    "IDEzLjYyNSA4LjQ4OCAyLjQ5NSAxNi42MjcgMi45NDYgMjYuNzgyIDAgNi43NS0xLjk1NSAxMy40\n",
    "MDYtNS44ODggMTMuNDA2LTEzLjYyNVY4Ni41SDU1LjUxM3YtMy40MDVIOTUuN2M3Ljc5MyAwIDEw\n",
    "LjY5Ni01LjQzNiAxMy40MDYtMTMuNTk0IDIuOC04LjM5OSAyLjY4LTE2LjQ3NiAwLTI3LjI1LTEu\n",
    "OTI1LTcuNzU4LTUuNjA0LTEzLjU5NC0xMy40MDYtMTMuNTk0ek03MC41NzUgOTMuMzEzYzIuNzgg\n",
    "MCA1LjAzMSAyLjI3OCA1LjAzMSA1LjA5NCAwIDIuODI3LTIuMjUxIDUuMTI1LTUuMDMxIDUuMTI1\n",
    "LTIuNzcgMC01LjAzMS0yLjI5OC01LjAzMS01LjEyNSAwLTIuODE2IDIuMjYxLTUuMDk0IDUuMDMx\n",
    "LTUuMDk0IiBzdHlsZT0iZmlsbDp1cmwoI2UpO2ZpbGwtb3BhY2l0eToxIi8+PGVsbGlwc2UgY3g9\n",
    "IjU1LjgxNyIgY3k9IjEyNy43MDEiIHJ4PSIzNS45MzEiIHJ5PSI2Ljk2NyIgc3R5bGU9Im9wYWNp\n",
    "dHk6LjQ0MzgyO2ZpbGw6dXJsKCNmKTtmaWxsLW9wYWNpdHk6MTtmaWxsLXJ1bGU6bm9uemVybztz\n",
    "dHJva2U6bm9uZTtzdHJva2Utd2lkdGg6MTUuNDE3NDtzdHJva2UtbWl0ZXJsaW1pdDo0O3N0cm9r\n",
    "ZS1kYXNoYXJyYXk6bm9uZTtzdHJva2Utb3BhY2l0eToxIi8+PC9zdmc+\n",
    "\"\n",
    "     style=\"display:block;margin:auto;width:10%\" alt=\"Python Logo\"/>\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align:center; font-size:200%;\">\n",
    " <b>Von Neuronalen Netzen zu Large Language Models</b>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"text-align:center;\">Dr. Matthias Hölzl</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37a7dc58003099",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Was wir bisher gelernt haben\n",
    "\n",
    "- Neuronale Netze können komplexe Muster lernen\n",
    "- Sie bestehen aus Neuronen, Gewichten und Aktivierungsfunktionen\n",
    "- Durch Training lernen sie, Vorhersagen zu machen\n",
    "- Wir haben sie für Zahlen und einfache Klassifikation genutzt\n",
    "\n",
    "**Aber**: Neuronale Netze können noch viel mehr!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f89ea34ca94ef5",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd3d6249a7a8c3",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4683a1498a3c176",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Neuronale Netze auf Text\n",
    "\n",
    "- **Frage**: Können neuronale Netze auch mit Text arbeiten?\n",
    "- **Problem**: Netze verarbeiten nur Zahlen, nicht Wörter\n",
    "- **Lösung**: Wörter in Zahlen umwandeln!\n",
    "- Das nennt man **Embeddings** (Einbettungen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9810322df2713541",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Was sind Embeddings?\n",
    "\n",
    "- Jedes Wort wird als Vektor (Liste von Zahlen) dargestellt\n",
    "- Ähnliche Wörter haben ähnliche Vektoren\n",
    "- **Beispiel**:\n",
    "  - \"König\" und \"Königin\" sind nahe beieinander\n",
    "  - \"Hund\" und \"Katze\" sind nahe beieinander\n",
    "  - \"König\" und \"Tisch\" sind weit auseinander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6bd2104765125d",
   "metadata": {
    "lang": "de"
   },
   "source": [
    "\n",
    "Vereinfachte Wort-Embeddings (2D zur Visualisierung)\n",
    "In der Realität haben Embeddings typischerweise 300-1000 Dimensionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa261d46e924486",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "word_embeddings = {\n",
    "    'king': np.array([0.8, 0.9]),\n",
    "    'queen': np.array([0.75, 0.85]),\n",
    "    'man': np.array([0.7, 0.3]),\n",
    "    'woman': np.array([0.65, 0.25]),\n",
    "    'dog': np.array([-0.4, 0.7]),\n",
    "    'cat': np.array([-0.35, 0.65]),\n",
    "    'table': np.array([-0.8, -0.6]),\n",
    "    'chair': np.array([-0.75, -0.65])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2923dc254e8d9c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c33a9aa7090d7367",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Attention: Die Geheimwaffe\n",
    "\n",
    "- **Problem**: Nicht alle Wörter im Satz sind gleich wichtig\n",
    "- **Lösung**: **Attention-Mechanismus**\n",
    "- Das Netzwerk lernt, auf wichtige Teile zu \"achten\"\n",
    "- Wie wenn Sie einen Text lesen und wichtige Wörter hervorheben"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cb49c20539f33d",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Beispiel: Attention\n",
    "\n",
    "**Satz**: \"Der Hund jagte die Katze durch den Park\"\n",
    "\n",
    "- Wenn wir über \"jagte\" nachdenken:\n",
    "  - Wichtig: \"Hund\" (wer jagt?)\n",
    "  - Wichtig: \"Katze\" (wen wird gejagt?)\n",
    "  - Weniger wichtig: \"der\", \"die\", \"durch\"\n",
    "\n",
    "Attention gewichtet automatisch, welche Wörter wichtig sind!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eafb03387b63a33",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Simplified attention visualization\n",
    "sentence = \"The dog chased the cat\".split()\n",
    "# Attention weights (simplified - showing which words matter for \"chased\")\n",
    "attention_weights = np.array([0.1, 0.4, 1.0, 0.1, 0.35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd79eb527247b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f55ee5c1e308dc2",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Von klein zu groß: Die Größenrevolution\n",
    "\n",
    "- Unsere neuronalen Netze: ~1.000-10.000 Parameter\n",
    "- Moderne neuronale Netze: Millionen von Parametern\n",
    "- **Large Language Models**: **Milliarden** von Parametern!\n",
    "\n",
    "| Modell | Parameter | Jahr |\n",
    "|--------|-----------|------|\n",
    "| GPT-2 | 1.5 Milliarden | 2019 |\n",
    "| GPT-3 | 175 Milliarden | 2020 |\n",
    "| GPT-4 | ~1 Billion (geschätzt) | 2023 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d1a17722af256b",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualization of parameter scales\n",
    "models = ['Unsere Netze\\nOur Networks', 'GPT-2', 'GPT-3', 'GPT-4\\n(geschätzt)']\n",
    "params = [10000, 1.5e9, 175e9, 1e12]  # in actual numbers\n",
    "params_display = [10, 1500, 175000, 1000000]  # in millions for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df17b39464e1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30bb49bc13c2927e",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Warum so groß?\n",
    "\n",
    "- **Mehr Parameter** = mehr Kapazität zum Lernen\n",
    "- LLMs werden auf **riesigen Textmengen** trainiert\n",
    "  - Bücher, Wikipedia, Websites, Code, ...\n",
    "  - Milliarden von Wörtern!\n",
    "- Sie lernen:\n",
    "  - Grammatik und Syntax\n",
    "  - Fakten und Wissen\n",
    "  - Schreibstile und Muster\n",
    "  - Logik und Schlussfolgerungen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31e78cdf32a7392",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Was können LLMs?\n",
    "\n",
    "- **Text generieren**: Geschichten, Artikel, Code schreiben\n",
    "- **Fragen beantworten**: Wissen abrufen und erklären\n",
    "- **Übersetzen**: Zwischen Sprachen übersetzen\n",
    "- **Zusammenfassen**: Lange Texte kurz zusammenfassen\n",
    "- **Code schreiben**: Programme in verschiedenen Sprachen\n",
    "- **Konversation**: Natürliche Unterhaltungen führen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67778d5b9d62e809",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Beispiele für LLMs\n",
    "\n",
    "- **GPT-4** (OpenAI): Sehr leistungsfähig, vielseitig\n",
    "- **Claude** (Anthropic): Gut bei langen Texten, hilfreich\n",
    "- **Llama 2** (Meta): Open Source, läuft lokal\n",
    "- **Gemini** (Google): Multimodal (Text + Bilder)\n",
    "\n",
    "Alle basieren auf denselben Grundprinzipien:\n",
    "Neuronale Netze + Embeddings + Attention!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7939c3cef857dc6d",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Die Kernbotschaft\n",
    "\n",
    "**LLMs sind neuronale Netze wie die, die Sie gebaut haben!**\n",
    "\n",
    "- Dieselben Grundprinzipien: Gewichte, Training, Muster lernen\n",
    "- Nur **viel größer** und auf **viel mehr Text** trainiert\n",
    "- Kombiniert mit **cleveren Techniken** (Embeddings, Attention)\n",
    "- Das Ergebnis: Systeme, die Sprache verstehen und generieren können\n",
    "\n",
    "**Im nächsten Abschnitt**: Lernen wir, wie man LLMs nutzt!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ea556b60790cd1",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Zusammenfassung\n",
    "\n",
    "- **Embeddings**: Wörter als Zahlen → Netze können damit arbeiten\n",
    "- **Attention**: Konzentrieren auf wichtige Teile des Textes\n",
    "- **Größe**: Von Tausenden zu Milliarden von Parametern\n",
    "- **Training**: Auf riesigen Textmengen lernen\n",
    "- **Fähigkeiten**: Text verstehen, generieren, übersetzen, ...\n",
    "\n",
    "**Sie haben schon die Grundlagen!** Jetzt nutzen wir große Modelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e03423667dbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "lang,tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
