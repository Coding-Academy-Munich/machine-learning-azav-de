{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9003f9b787891ad8",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "<img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRw\n",
    "Oi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMTExLjE2MSIgaGVpZ2h0PSIxMzQuNjY4\n",
    "IiB2ZXJzaW9uPSIxLjAiPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYyI+PHN0b3Agb2Zmc2V0\n",
    "PSIwIiBzdHlsZT0ic3RvcC1jb2xvcjojYjhiOGI4O3N0b3Atb3BhY2l0eTouNDk4MDM5MjIiLz48\n",
    "c3RvcCBvZmZzZXQ9IjEiIHN0eWxlPSJzdG9wLWNvbG9yOiM3ZjdmN2Y7c3RvcC1vcGFjaXR5OjAi\n",
    "Lz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYSI+PHN0b3Agb2Zmc2V0PSIw\n",
    "IiBzdHlsZT0ic3RvcC1jb2xvcjojZmZkNDNiO3N0b3Atb3BhY2l0eToxIi8+PHN0b3Agb2Zmc2V0\n",
    "PSIxIiBzdHlsZT0ic3RvcC1jb2xvcjojZmZlODczO3N0b3Atb3BhY2l0eToxIi8+PC9saW5lYXJH\n",
    "cmFkaWVudD48bGluZWFyR3JhZGllbnQgaWQ9ImIiPjxzdG9wIG9mZnNldD0iMCIgc3R5bGU9InN0\n",
    "b3AtY29sb3I6IzVhOWZkNDtzdG9wLW9wYWNpdHk6MSIvPjxzdG9wIG9mZnNldD0iMSIgc3R5bGU9\n",
    "InN0b3AtY29sb3I6IzMwNjk5ODtzdG9wLW9wYWNpdHk6MSIvPjwvbGluZWFyR3JhZGllbnQ+PGxp\n",
    "bmVhckdyYWRpZW50IHhsaW5rOmhyZWY9IiNhIiBpZD0iZSIgeDE9IjE1MC45NjEiIHgyPSIxMTIu\n",
    "MDMxIiB5MT0iMTkyLjM1MiIgeTI9IjEzNy4yNzMiIGdyYWRpZW50VHJhbnNmb3JtPSJtYXRyaXgo\n",
    "LjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRVbml0cz0idXNlclNw\n",
    "YWNlT25Vc2UiLz48bGluZWFyR3JhZGllbnQgeGxpbms6aHJlZj0iI2IiIGlkPSJkIiB4MT0iMjYu\n",
    "NjQ5IiB4Mj0iMTM1LjY2NSIgeTE9IjIwLjYwNCIgeTI9IjExNC4zOTgiIGdyYWRpZW50VHJhbnNm\n",
    "b3JtPSJtYXRyaXgoLjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRV\n",
    "bml0cz0idXNlclNwYWNlT25Vc2UiLz48cmFkaWFsR3JhZGllbnQgeGxpbms6aHJlZj0iI2MiIGlk\n",
    "PSJmIiBjeD0iNjEuNTE5IiBjeT0iMTMyLjI4NiIgcj0iMjkuMDM3IiBmeD0iNjEuNTE5IiBmeT0i\n",
    "MTMyLjI4NiIgZ3JhZGllbnRUcmFuc2Zvcm09Im1hdHJpeCgwIC0uMjM5OTUgMS4wNTQ2NyAwIC04\n",
    "My43IDE0Mi40NjIpIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIvPjwvZGVmcz48cGF0\n",
    "aCBkPSJNNTQuOTE5IDBjLTQuNTg0LjAyMi04Ljk2MS40MTMtMTIuODEzIDEuMDk1QzMwLjc2IDMu\n",
    "MDk5IDI4LjcgNy4yOTUgMjguNyAxNS4wMzJ2MTAuMjE5aDI2LjgxM3YzLjQwNkgxOC42MzhjLTcu\n",
    "NzkzIDAtMTQuNjE2IDQuNjg0LTE2Ljc1IDEzLjU5NC0yLjQ2MiAxMC4yMTMtMi41NzEgMTYuNTg2\n",
    "IDAgMjcuMjUgMS45MDUgNy45MzggNi40NTcgMTMuNTk0IDE0LjI1IDEzLjU5NGg5LjIxOHYtMTIu\n",
    "MjVjMC04Ljg1IDcuNjU3LTE2LjY1NyAxNi43NS0xNi42NTdoMjYuNzgyYzcuNDU0IDAgMTMuNDA2\n",
    "LTYuMTM4IDEzLjQwNi0xMy42MjV2LTI1LjUzYzAtNy4yNjctNi4xMy0xMi43MjYtMTMuNDA2LTEz\n",
    "LjkzOEM2NC4yODIuMzI4IDU5LjUwMi0uMDIgNTQuOTE4IDBtLTE0LjUgOC4yMmMyLjc3IDAgNS4w\n",
    "MzEgMi4yOTggNS4wMzEgNS4xMjUgMCAyLjgxNi0yLjI2MiA1LjA5My01LjAzMSA1LjA5My0yLjc4\n",
    "IDAtNS4wMzEtMi4yNzctNS4wMzEtNS4wOTMgMC0yLjgyNyAyLjI1MS01LjEyNSA1LjAzLTUuMTI1\n",
    "IiBzdHlsZT0iZmlsbDp1cmwoI2QpO2ZpbGwtb3BhY2l0eToxIi8+PHBhdGggZD0iTTg1LjYzOCAy\n",
    "OC42NTd2MTEuOTA2YzAgOS4yMzEtNy44MjYgMTctMTYuNzUgMTdINDIuMTA2Yy03LjMzNiAwLTEz\n",
    "LjQwNiA2LjI3OS0xMy40MDYgMTMuNjI1Vjk2LjcyYzAgNy4yNjYgNi4zMTkgMTEuNTQgMTMuNDA2\n",
    "IDEzLjYyNSA4LjQ4OCAyLjQ5NSAxNi42MjcgMi45NDYgMjYuNzgyIDAgNi43NS0xLjk1NSAxMy40\n",
    "MDYtNS44ODggMTMuNDA2LTEzLjYyNVY4Ni41SDU1LjUxM3YtMy40MDVIOTUuN2M3Ljc5MyAwIDEw\n",
    "LjY5Ni01LjQzNiAxMy40MDYtMTMuNTk0IDIuOC04LjM5OSAyLjY4LTE2LjQ3NiAwLTI3LjI1LTEu\n",
    "OTI1LTcuNzU4LTUuNjA0LTEzLjU5NC0xMy40MDYtMTMuNTk0ek03MC41NzUgOTMuMzEzYzIuNzgg\n",
    "MCA1LjAzMSAyLjI3OCA1LjAzMSA1LjA5NCAwIDIuODI3LTIuMjUxIDUuMTI1LTUuMDMxIDUuMTI1\n",
    "LTIuNzcgMC01LjAzMS0yLjI5OC01LjAzMS01LjEyNSAwLTIuODE2IDIuMjYxLTUuMDk0IDUuMDMx\n",
    "LTUuMDk0IiBzdHlsZT0iZmlsbDp1cmwoI2UpO2ZpbGwtb3BhY2l0eToxIi8+PGVsbGlwc2UgY3g9\n",
    "IjU1LjgxNyIgY3k9IjEyNy43MDEiIHJ4PSIzNS45MzEiIHJ5PSI2Ljk2NyIgc3R5bGU9Im9wYWNp\n",
    "dHk6LjQ0MzgyO2ZpbGw6dXJsKCNmKTtmaWxsLW9wYWNpdHk6MTtmaWxsLXJ1bGU6bm9uemVybztz\n",
    "dHJva2U6bm9uZTtzdHJva2Utd2lkdGg6MTUuNDE3NDtzdHJva2UtbWl0ZXJsaW1pdDo0O3N0cm9r\n",
    "ZS1kYXNoYXJyYXk6bm9uZTtzdHJva2Utb3BhY2l0eToxIi8+PC9zdmc+\n",
    "\"\n",
    "     style=\"display:block;margin:auto;width:10%\" alt=\"Python Logo\"/>\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align:center; font-size:200%;\">\n",
    " <b>Retrieval-Augmented Generation (RAG)</b>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"text-align:center;\">Dr. Matthias Hölzl</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e12f792cfb83074",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Das Problem mit LLMs\n",
    "\n",
    "- LLMs sind sehr leistungsfähig\n",
    "- Aber sie haben auch Probleme:\n",
    "  - **Halluzinationen**: Sie \"erfinden\" manchmal Fakten\n",
    "  - **Fehlendes Wissen**: Wissen ist auf Trainingsdaten begrenzt\n",
    "- Besonders bei spezifischem Wissen (z.B. Firmendaten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80991aa92e2ca81",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "keep",
     "subslide"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230acfe8e4018705",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01dcdd8163bafd9",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"mistralai/ministral-14b-2512\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590fce20d7e31088",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Beispiel: Halluzination / Fehlendes Wissen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a1394d8dbb785",
   "metadata": {
    "lang": "de"
   },
   "source": [
    "\n",
    "Spezifische Frage zum Kursinhalt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b24df0a9cfbf992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee87e2035fe00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e3a5424e24d4fc2",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Was ist RAG?\n",
    "\n",
    "**Retrieval-Augmented Generation** = Abrufen + Generieren\n",
    "\n",
    "1. **Retrieval**: Relevante Dokumente/Informationen finden\n",
    "2. **Augmentation**: Kontext zum Prompt hinzufügen\n",
    "3. **Generation**: LLM antwortet basierend auf echten Daten\n",
    "\n",
    "**Analogie**: Prüfung mit offenem Buch statt aus dem Gedächtnis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6c04fd23392a8",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## RAG-Architektur\n",
    "\n",
    "```\n",
    "Benutzer-Frage\n",
    "    ↓\n",
    "1. Relevante Dokumente suchen\n",
    "    ↓\n",
    "2. Kontext zum Prompt hinzufügen\n",
    "    ↓\n",
    "3. LLM mit Kontext aufrufen\n",
    "    ↓\n",
    "Antwort basierend auf echten Daten\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d43834f7accb0",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Beispiel: Mit vs. Ohne Kontext\n",
    "\n",
    "Nehmen wir an, wir haben ein Dokument mit folgendem Inhalt als Kontext\n",
    "geladen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e01fe3b7051d6a",
   "metadata": {
    "lang": "de",
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "context = \"\"\"\\\n",
    "In diesem Kurs lernen Sie über lineare Regression in Kapitel 3.\n",
    "Lineare Regression ist eine Methode, um lineare Beziehungen zu modellieren.\n",
    "Wir verwenden die Normalgleichung und den Mean Squared Error.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b74a3b8ec6a8aa",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Ohne Kontext\n",
    "\n",
    "Wie wir gesehen haben, kann das LLM ohne zusätzlichen Kontext die Antwort\n",
    "nicht kennen:\n",
    "\n",
    "```python\n",
    "response_no_context = llm.invoke(\"Was steht in Kapitel 3 über lineare Regression?\")\n",
    "```\n",
    "\n",
    "**Antwort:**\n",
    "```text\n",
    "Da ich keine direkten Websuche- oder Dateizugriffsfunktionen habe, kann ich\n",
    "den Inhalt von **Kapitel 3 deines Kurses zur linearen Regression** nicht\n",
    "direkt aus einem Kursmaterial (z. B. PDF, Online-Dokument oder Lernplattform)\n",
    "für dich herausfinden.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07df998aba974600",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "### Mit Kontext\n",
    "\n",
    "Jetzt fügen wir den Kontext hinzu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e78b7866e883fe",
   "metadata": {
    "lang": "de",
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "prompt_with_context = f\"\"\"\\\n",
    "Basiere deine Antwort NUR auf folgenden Informationen:\n",
    "\n",
    "{context}\n",
    "\n",
    "Frage: Was steht in Kapitel 3 über lineare Regression?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6fd470c1abd469",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "keep",
     "subslide"
    ]
   },
   "outputs": [],
   "source": [
    "response_with_context = llm.invoke(prompt_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b952e93355b0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a7832b33a93d7c7",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Wie finden wir den passenden Kontext?\n",
    "\n",
    "- Wir haben viele Dokumente\n",
    "- Welche Granularität der Dokumente sollen wir verwenden?\n",
    "  - Vollständige Dokumente?\n",
    "  - Absätze?\n",
    "  - Sätze?\n",
    "- Wie finden wir die relevanten Passagen?<br>\n",
    "  Naheliegende Ansätze:\n",
    "  - Annotation mit Schlüsselwörtern\n",
    "  - Volltextsuche (aus dem Prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c711c950c64528",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Probleme bei naheliegenden Ansätzen\n",
    "\n",
    "- **Schlüsselwörter**:\n",
    "  - Müssen manuell gepflegt werden (oder automatisch: fehleranfällig)\n",
    "  - Ignorieren viele Aspekte des Textes (bei längeren Dokumenten)\n",
    "- **Volltextsuche und Schlüsselwörter**:\n",
    "  - Abhängig von exakten Begriffen\n",
    "  - Ignorieren semantische Ähnlichkeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946957eea78ec29b",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Vektor-Suche\n",
    "\n",
    "<div style=\"float:right;width:40%;\">\n",
    "  <img src=\"img/cosine-distance.png\" style=\"float:right;width:50%\"/>\n",
    "  <img src=\"img/vector-difference.png\" style=\"float:left;width:50%\"/>\n",
    "</div>\n",
    "<div style=\"width:60%;\">\n",
    "<br>\n",
    "<ul>\n",
    "  <li>Embeddings: Repräsentation von Text als Vektoren</li>\n",
    "  <li>Ähnlichkeit von Vektoren mathematisch definierbar</li>\n",
    "  <ul>\n",
    "    <li>Beispiel: $|\\vec a - \\vec b|$ (Euklidische Distanz)</li>\n",
    "    <li>Oft besser: Kosinus-Ähnlichkeit<br>(Winkel zwischen Vektoren)</li>\n",
    "  </ul>\n",
    "  <li>Idee: \"ähnliche\" Texte → \"ähnliche\" Vektoren</li>\n",
    "  <li>Semantische Suche: Finde ähnliche Vektoren</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0006199f2addd",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## RAG-Komponenten\n",
    "\n",
    "1. **Dokument-Speicher**: Ihre Dokumente/Daten\n",
    "2. **Embedding-Modell**: Text → Vektoren\n",
    "3. **Vektor-Datenbank**: Für schnelle Suche\n",
    "4. **Retriever**: Findet relevante Dokumente\n",
    "5. **LLM**: Generiert Antwort mit Kontext\n",
    "\n",
    "**LangChain** bringt alle Komponenten zusammen!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479fbe6b5f36290b",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Anwendungsfälle für RAG\n",
    "\n",
    "- **Dokumenten-Q&A**: Fragen zu Handbüchern, Verträgen, etc.\n",
    "- **Kundenservice**: Infos aus Wissensdatenbank\n",
    "- **Forschungsassistent**: Durchsucht Papers/Artikel\n",
    "- **Code-Dokumentation**: Hilfe für Code-Repositories\n",
    "- **Firmen-Chatbot**: Zugriff auf interne Dokumente\n",
    "\n",
    "**Immer wenn**: Spezifisches Wissen benötigt wird!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3a700926fec818",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Alternative: Fine-Tuning\n",
    "\n",
    "- **Fine-Tuning** = Modell mit eigenen Daten weitertrainieren\n",
    "- Das Modell \"lernt\" neue Muster und Verhaltensweisen\n",
    "- Beispiele:\n",
    "  - Bestimmter Schreibstil (formell, technisch, etc.)\n",
    "  - Domänenspezifische Fachsprache\n",
    "  - Spezielle Ausgabeformate\n",
    "- **Wichtig**: Wissen wird Teil des Modells selbst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a7b79983dbe188",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## RAG vs. Fine-Tuning: Vergleich\n",
    "\n",
    "| Aspekt | RAG | Fine-Tuning |\n",
    "|--------|-----|-------------|\n",
    "| **Stärke** | Faktenwissen | Verhalten/Stil |\n",
    "| **Aktualisierung** | Dokumente austauschen | Neu trainieren |\n",
    "| **Kosten** | Gering | Höher |\n",
    "| **Transparenz** | Quellen sichtbar | Black Box |\n",
    "| **Konsistenz** | Variiert mit Retrieval | Sehr konsistent |\n",
    "| **Latenz** | Retrieval-Overhead | Schneller |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d0ff12a149eb5",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Wann welchen Ansatz wählen?\n",
    "\n",
    "<div style=\"width:50%;float:left;\">\n",
    "<br>\n",
    "<b>RAG ist besser für:</b>\n",
    "<ul>\n",
    "  <li>Aktuelle Fakten und Dokumente</li>\n",
    "  <li>Häufig wechselnde Informationen</li>\n",
    "  <li>Nachvollziehbarkeit wichtig (Quellen)</li>\n",
    "  <li>Firmen-/Kundendaten</li>\n",
    "</ul>\n",
    "</div>\n",
    "<div style=\"width:45%;float:left;\">\n",
    "<br>\n",
    "<b>Fine-Tuning ist besser für:</b>\n",
    "<ul>\n",
    "  <li>Neuer Schreibstil oder Ton</li>\n",
    "  <li>Domänenspezifische Sprache</li>\n",
    "  <li>Konsistente Ausgabeformate</li>\n",
    "  <li>Wenn Retrieval-Latenz problematisch ist</li>\n",
    "</ul>\n",
    "</div>\n",
    "<div style=\"clear:both;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928399fbda23241c",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Wie LangChain RAG vereinfacht\n",
    "\n",
    "**Ohne Framework**:\n",
    "- Dokumente laden und chunken\n",
    "- Embeddings manuell erstellen\n",
    "- Vektor-Datenbank einrichten\n",
    "- Retrieval-Logik programmieren\n",
    "- LLM-Integration schreiben\n",
    "- ~200-300 Zeilen Code\n",
    "\n",
    "**Mit LangChain**:\n",
    "- Komponenten zusammenstecken\n",
    "- ~30-50 Zeilen Code\n",
    "\n",
    "**Darum nutzen wir LangChain von Anfang an!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e2d31cdcebabe",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Was wir lernen werden\n",
    "\n",
    "1. **Document Loaders**: Dokumente aus verschiedenen Quellen laden\n",
    "2. **Text Chunking**: Dokumente in handhabbare Stücke aufteilen\n",
    "3. **Vector Embeddings**: Wie Text als Vektoren dargestellt wird\n",
    "4. **ChromaDB**: Einfache Vektor-Datenbank\n",
    "5. **RAG mit LangChain**: Alles zusammenbauen\n",
    "6. **Workshop**: Eigenes RAG-System mit Gradio-UI\n",
    "\n",
    "**Ziel**: Ein funktionierendes Q&A-System über Ihre eigenen Dokumente!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7edacf65f7b4361",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Zusammenfassung\n",
    "\n",
    "- **Problem**: LLMs halluzinieren bei spezifischem Wissen\n",
    "- **Lösung**: RAG - Abrufen + Generieren\n",
    "- **Wie**: Relevante Dokumente finden und als Kontext nutzen\n",
    "- **Vorteil**: Präzise Antworten mit echten Daten\n",
    "- **LangChain**: Macht RAG einfach\n",
    "\n",
    "**Nächster Schritt**: Dokumente laden mit Document Loaders!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e03423667dbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,lang,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
