{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e26b1a1c67e25906",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "<img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRw\n",
    "Oi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMTExLjE2MSIgaGVpZ2h0PSIxMzQuNjY4\n",
    "IiB2ZXJzaW9uPSIxLjAiPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYyI+PHN0b3Agb2Zmc2V0\n",
    "PSIwIiBzdHlsZT0ic3RvcC1jb2xvcjojYjhiOGI4O3N0b3Atb3BhY2l0eTouNDk4MDM5MjIiLz48\n",
    "c3RvcCBvZmZzZXQ9IjEiIHN0eWxlPSJzdG9wLWNvbG9yOiM3ZjdmN2Y7c3RvcC1vcGFjaXR5OjAi\n",
    "Lz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYSI+PHN0b3Agb2Zmc2V0PSIw\n",
    "IiBzdHlsZT0ic3RvcC1jb2xvcjojZmZkNDNiO3N0b3Atb3BhY2l0eToxIi8+PHN0b3Agb2Zmc2V0\n",
    "PSIxIiBzdHlsZT0ic3RvcC1jb2xvcjojZmZlODczO3N0b3Atb3BhY2l0eToxIi8+PC9saW5lYXJH\n",
    "cmFkaWVudD48bGluZWFyR3JhZGllbnQgaWQ9ImIiPjxzdG9wIG9mZnNldD0iMCIgc3R5bGU9InN0\n",
    "b3AtY29sb3I6IzVhOWZkNDtzdG9wLW9wYWNpdHk6MSIvPjxzdG9wIG9mZnNldD0iMSIgc3R5bGU9\n",
    "InN0b3AtY29sb3I6IzMwNjk5ODtzdG9wLW9wYWNpdHk6MSIvPjwvbGluZWFyR3JhZGllbnQ+PGxp\n",
    "bmVhckdyYWRpZW50IHhsaW5rOmhyZWY9IiNhIiBpZD0iZSIgeDE9IjE1MC45NjEiIHgyPSIxMTIu\n",
    "MDMxIiB5MT0iMTkyLjM1MiIgeTI9IjEzNy4yNzMiIGdyYWRpZW50VHJhbnNmb3JtPSJtYXRyaXgo\n",
    "LjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRVbml0cz0idXNlclNw\n",
    "YWNlT25Vc2UiLz48bGluZWFyR3JhZGllbnQgeGxpbms6aHJlZj0iI2IiIGlkPSJkIiB4MT0iMjYu\n",
    "NjQ5IiB4Mj0iMTM1LjY2NSIgeTE9IjIwLjYwNCIgeTI9IjExNC4zOTgiIGdyYWRpZW50VHJhbnNm\n",
    "b3JtPSJtYXRyaXgoLjU2MjU0IDAgMCAuNTY3OTcgLTE0Ljk5MSAtMTEuNzAyKSIgZ3JhZGllbnRV\n",
    "bml0cz0idXNlclNwYWNlT25Vc2UiLz48cmFkaWFsR3JhZGllbnQgeGxpbms6aHJlZj0iI2MiIGlk\n",
    "PSJmIiBjeD0iNjEuNTE5IiBjeT0iMTMyLjI4NiIgcj0iMjkuMDM3IiBmeD0iNjEuNTE5IiBmeT0i\n",
    "MTMyLjI4NiIgZ3JhZGllbnRUcmFuc2Zvcm09Im1hdHJpeCgwIC0uMjM5OTUgMS4wNTQ2NyAwIC04\n",
    "My43IDE0Mi40NjIpIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIvPjwvZGVmcz48cGF0\n",
    "aCBkPSJNNTQuOTE5IDBjLTQuNTg0LjAyMi04Ljk2MS40MTMtMTIuODEzIDEuMDk1QzMwLjc2IDMu\n",
    "MDk5IDI4LjcgNy4yOTUgMjguNyAxNS4wMzJ2MTAuMjE5aDI2LjgxM3YzLjQwNkgxOC42MzhjLTcu\n",
    "NzkzIDAtMTQuNjE2IDQuNjg0LTE2Ljc1IDEzLjU5NC0yLjQ2MiAxMC4yMTMtMi41NzEgMTYuNTg2\n",
    "IDAgMjcuMjUgMS45MDUgNy45MzggNi40NTcgMTMuNTk0IDE0LjI1IDEzLjU5NGg5LjIxOHYtMTIu\n",
    "MjVjMC04Ljg1IDcuNjU3LTE2LjY1NyAxNi43NS0xNi42NTdoMjYuNzgyYzcuNDU0IDAgMTMuNDA2\n",
    "LTYuMTM4IDEzLjQwNi0xMy42MjV2LTI1LjUzYzAtNy4yNjctNi4xMy0xMi43MjYtMTMuNDA2LTEz\n",
    "LjkzOEM2NC4yODIuMzI4IDU5LjUwMi0uMDIgNTQuOTE4IDBtLTE0LjUgOC4yMmMyLjc3IDAgNS4w\n",
    "MzEgMi4yOTggNS4wMzEgNS4xMjUgMCAyLjgxNi0yLjI2MiA1LjA5My01LjAzMSA1LjA5My0yLjc4\n",
    "IDAtNS4wMzEtMi4yNzctNS4wMzEtNS4wOTMgMC0yLjgyNyAyLjI1MS01LjEyNSA1LjAzLTUuMTI1\n",
    "IiBzdHlsZT0iZmlsbDp1cmwoI2QpO2ZpbGwtb3BhY2l0eToxIi8+PHBhdGggZD0iTTg1LjYzOCAy\n",
    "OC42NTd2MTEuOTA2YzAgOS4yMzEtNy44MjYgMTctMTYuNzUgMTdINDIuMTA2Yy03LjMzNiAwLTEz\n",
    "LjQwNiA2LjI3OS0xMy40MDYgMTMuNjI1Vjk2LjcyYzAgNy4yNjYgNi4zMTkgMTEuNTQgMTMuNDA2\n",
    "IDEzLjYyNSA4LjQ4OCAyLjQ5NSAxNi42MjcgMi45NDYgMjYuNzgyIDAgNi43NS0xLjk1NSAxMy40\n",
    "MDYtNS44ODggMTMuNDA2LTEzLjYyNVY4Ni41SDU1LjUxM3YtMy40MDVIOTUuN2M3Ljc5MyAwIDEw\n",
    "LjY5Ni01LjQzNiAxMy40MDYtMTMuNTk0IDIuOC04LjM5OSAyLjY4LTE2LjQ3NiAwLTI3LjI1LTEu\n",
    "OTI1LTcuNzU4LTUuNjA0LTEzLjU5NC0xMy40MDYtMTMuNTk0ek03MC41NzUgOTMuMzEzYzIuNzgg\n",
    "MCA1LjAzMSAyLjI3OCA1LjAzMSA1LjA5NCAwIDIuODI3LTIuMjUxIDUuMTI1LTUuMDMxIDUuMTI1\n",
    "LTIuNzcgMC01LjAzMS0yLjI5OC01LjAzMS01LjEyNSAwLTIuODE2IDIuMjYxLTUuMDk0IDUuMDMx\n",
    "LTUuMDk0IiBzdHlsZT0iZmlsbDp1cmwoI2UpO2ZpbGwtb3BhY2l0eToxIi8+PGVsbGlwc2UgY3g9\n",
    "IjU1LjgxNyIgY3k9IjEyNy43MDEiIHJ4PSIzNS45MzEiIHJ5PSI2Ljk2NyIgc3R5bGU9Im9wYWNp\n",
    "dHk6LjQ0MzgyO2ZpbGw6dXJsKCNmKTtmaWxsLW9wYWNpdHk6MTtmaWxsLXJ1bGU6bm9uemVybztz\n",
    "dHJva2U6bm9uZTtzdHJva2Utd2lkdGg6MTUuNDE3NDtzdHJva2UtbWl0ZXJsaW1pdDo0O3N0cm9r\n",
    "ZS1kYXNoYXJyYXk6bm9uZTtzdHJva2Utb3BhY2l0eToxIi8+PC9zdmc+\n",
    "\"\n",
    "     style=\"display:block;margin:auto;width:10%\" alt=\"Python Logo\"/>\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align:center; font-size:200%;\">\n",
    " <b>Streaming mit Generatoren</b>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"text-align:center;\">Dr. Matthias Hölzl</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b17a3c6b16725ac",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Warum Streaming?\n",
    "\n",
    "**Problem:** LLM-Antworten können lang sein\n",
    "\n",
    "- Der Benutzer wartet... und wartet...\n",
    "- Erst am Ende erscheint die komplette Antwort\n",
    "- Das fühlt sich langsam an!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcad8b8ee342c3c",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Die Lösung: Streaming\n",
    "\n",
    "- Zeige die Antwort **während sie generiert wird**\n",
    "- Wie ein Brief, den man Wort für Wort liest\n",
    "- Der Benutzer sieht sofort, dass etwas passiert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137c255620ec8c08",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Das Schlüsselwort `yield`\n",
    "\n",
    "Normale Funktionen mit `return`:\n",
    "\n",
    "- Funktion gibt **einen** Wert zurück\n",
    "- Funktion **endet** sofort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f346d5ec880a7a95",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def normal_function():\n",
    "    return \"Erster Wert\"\n",
    "    return \"Zweiter Wert\"  # Wird nie erreicht!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b377af85ae97d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b7eb6ebe4951628",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Funktionen mit `yield`\n",
    "\n",
    "- Funktion gibt einen Wert zurück und **pausiert**\n",
    "- Bei der nächsten Anfrage macht sie **weiter**\n",
    "- Kann **mehrere Werte** nacheinander liefern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916267b13745a213",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def generator_function():\n",
    "    yield \"Erster Wert\"\n",
    "    yield \"Zweiter Wert\"\n",
    "    yield \"Dritter Wert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01359f974b8a9d2",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Generator-Objekte\n",
    "\n",
    "Ein Aufruf einer Generator-Funktion gibt ein **Generator-Objekt** zurück:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25f7f3c663cd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e3781e40937ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9a184652c39a90d",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Werte aus einem Generator holen\n",
    "\n",
    "Mit einer `for`-Schleife können wir alle Werte durchlaufen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bbb07363c4928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "374b68da8e184501",
   "metadata": {
    "lang": "de",
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Ein etwas komplizierterer Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c48492d110eaf94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe96c1f536582fb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide",
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\\\n",
    "# Introduction to Python Lists\n",
    "\n",
    "Python lists are a fundamental data structure used to store a collection of \\\n",
    "items. They are ordered, mutable, and allow duplicate elements. Lists are \\\n",
    "defined by enclosing sequence of items in square brackets `[]`, separated by \\\n",
    "commas.\n",
    "\n",
    "## Creating a List\n",
    "\n",
    "You can create a list with various data types, including integers, floats, \\\n",
    "strings, and even other lists. Here are a few examples:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1988db629402a96",
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a6c448529b01ed3",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Generatoren in Gradio\n",
    "\n",
    "Gradio unterstützt Generator-Funktionen automatisch!\n",
    "\n",
    "- Bei jedem `yield` wird die Chat-Oberfläche aktualisiert\n",
    "- Der Benutzer sieht die Antwort wachsen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75d158880cae59f",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Das Muster für Streaming\n",
    "\n",
    "```python\n",
    "def streaming_chat(message, history):\n",
    "    full_response = \"\"\n",
    "    for chunk in ...:  # Chunks vom LLM\n",
    "        full_response += chunk\n",
    "        yield full_response  # Zeige bisherige Antwort\n",
    "```\n",
    "\n",
    "Wichtig: Wir geben immer die **gesamte bisherige Antwort** zurück!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b3ba31e053bb22",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Streaming mit LangChain\n",
    "\n",
    "LangChain bietet `llm.stream()` statt `llm.invoke()`:\n",
    "\n",
    "- Gibt Chunks zurück (kleine Teile der Antwort)\n",
    "- Jeder Chunk hat `.content` mit dem Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b64f2c0a5ae6e",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce35827a2adb266e",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01dcdd8163bafd9",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"mistralai/ministral-14b-2512\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3daa6708a61254",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Beispiel: Streaming in Aktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921ccbc4d3c8f70c",
   "metadata": {
    "lang": "de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4013163abce867b",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Ein einfacher Chatbot\n",
    "\n",
    "Zuerst erstellen wir einen einfachen Chatbot ohne Streaming.\n",
    "\n",
    "Diesmal speichern wir die Listen der Nachrichten nicht im Chatbot-Objekt,\n",
    "sondern verwenden die History von Gradio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5777c88c8865f5f3",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b26176b2194a47d",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def create_llm():\n",
    "    return ChatOpenAI(\n",
    "        api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        model=\"mistralai/ministral-14b-2512\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a310f83f2f4dc1",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Warum Gradios History verwenden?\n",
    "\n",
    "Gradio bietet Funktionen wie **Nachricht löschen** und **Antwort neu generieren**\n",
    "\n",
    "- Damit diese korrekt funktionieren, müssen wir Gradios History verwenden\n",
    "- Wir speichern die Nachrichten nicht mehr im Chatbot-Objekt\n",
    "- `history_to_messages()` konvertiert zwischen Gradio- und LangChain-Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a78fa2a04def15",
   "metadata": {
    "lines_to_next_cell": 1,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "keep",
     "subslide"
    ]
   },
   "outputs": [],
   "source": [
    "def history_to_messages(history, system_prompt=None):\n",
    "    \"\"\"Convert Gradio history to LangChain messages.\"\"\"\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append(SystemMessage(content=system_prompt))\n",
    "    for msg in history:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            messages.append(HumanMessage(content=msg[\"content\"]))\n",
    "        else:\n",
    "            messages.append(AIMessage(content=msg[\"content\"]))\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7041a7363f566b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "keep",
     "subslide"
    ]
   },
   "outputs": [],
   "source": [
    "class SimpleChatbot:\n",
    "    \"\"\"A simple chatbot using OpenRouter.\"\"\"\n",
    "\n",
    "    def __init__(self, system_prompt=None):\n",
    "        self.llm = create_llm()\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "    def chat(self, user_message, history):\n",
    "        \"\"\"Send a message and get a response.\"\"\"\n",
    "        messages = history_to_messages(history, self.system_prompt)\n",
    "        messages.append(HumanMessage(content=user_message))\n",
    "        response = self.llm.invoke(messages)\n",
    "        return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf7bb879902c4a",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Nicht-Streaming Chatbot mit Gradio\n",
    "\n",
    "Beobachten Sie: Die Antwort erscheint erst nach einer Wartezeit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ef8acb83a73dc",
   "metadata": {
    "lang": "de",
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "simple_bot = SimpleChatbot(\"Du bist ein hilfreicher Assistent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe967378f037c777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d0d541f5be6d3",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab8c83b03522fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3c652ab05c6531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28a1ec13a8c83afa",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Streaming zum Chatbot hinzufügen\n",
    "\n",
    "Wir erweitern unseren `SimpleChatbot` mit einer `stream()`-Methode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5702ee07564f13ea",
   "metadata": {
    "tags": [
     "start"
    ]
   },
   "outputs": [],
   "source": [
    "class SimpleChatbot:\n",
    "    def __init__(self, system_prompt=None):\n",
    "        self.llm = create_llm()\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "    def chat(self, user_message, history):\n",
    "        \"\"\"Send a message and get a response.\"\"\"\n",
    "        messages = history_to_messages(history, self.system_prompt)\n",
    "        messages.append(HumanMessage(content=user_message))\n",
    "        response = self.llm.invoke(messages)\n",
    "        return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b9d90e1dd0e0c7",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "source": [
    "\n",
    "## Streaming Chatbot mit Gradio\n",
    "\n",
    "Jetzt sehen wir die Antwort Wort für Wort entstehen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b1ebc36ef1300",
   "metadata": {
    "lang": "de",
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "streaming_bot = SimpleChatbot(\"Du bist ein hilfreicher Assistent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8501925f9e41c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b575576473196",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c690579e64cd779b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2c919957ec95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71bbe8dd567148a0",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Workshop: Streaming-Chatbot erweitern\n",
    "\n",
    "**Aufgabe**: Erweitern Sie den Streaming-Chatbot!\n",
    "\n",
    "1. Fügen Sie eine Provider-Auswahl hinzu (openrouter, openai, anthropic)\n",
    "2. Fügen Sie eine System-Prompt-Auswahl hinzu\n",
    "3. Der Benutzer soll sowohl Provider als auch System-Prompt wählen können\n",
    "4. **Bonus**: Zeigen Sie an, wie viele Zeichen bereits generiert wurden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfbdae15f3d4d8e",
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "keep",
     "subslide"
    ]
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPTS = {\n",
    "    \"Helpful Assistant\": \"You are a helpful assistant.\",\n",
    "    \"Python Tutor\": \"You are a friendly Python tutor who explains concepts simply.\",\n",
    "    \"Pirate\": \"You are a pirate. Answer all questions like a pirate would.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feced98429e4578e",
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9cb3360220f6a6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "subslide"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc911c0769befb98",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "start",
     "subslide"
    ]
   },
   "outputs": [],
   "source": [
    "def extended_streaming_chat(message, history, provider, system_prompt_name):\n",
    "    \"\"\"Streaming chatbot with provider and system prompt selection.\"\"\"\n",
    "    # TODO: Implementieren Sie den Streaming-Chatbot\n",
    "    # Hint: Erstellen Sie für jede Kombination aus Provider und System-Prompt\n",
    "    #       eine eigene Chatbot-Instanz\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0712fd6590b65bf",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "start",
     "subslide"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Erstellen Sie das ChatInterface mit beiden Dropdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4413a2ec660fc39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a886339fc6eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0133375228cff1b9",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slide"
    ]
   },
   "source": [
    "\n",
    "## Zusammenfassung\n",
    "\n",
    "- **`yield`** pausiert eine Funktion und gibt einen Wert zurück\n",
    "- **Generator-Funktionen** können mehrere Werte nacheinander liefern\n",
    "- **Gradio** aktualisiert die UI bei jedem `yield`\n",
    "- **`llm.stream()`** liefert die Antwort in kleinen Chunks\n",
    "- **Streaming** macht Chatbots reaktiver und benutzerfreundlicher"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "lang,tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
